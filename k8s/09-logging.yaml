# ELK日志系统配置
# ELK Logging System Configuration

# Elasticsearch持久化存储
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: elasticsearch-pvc
  namespace: digital-employee
  labels:
    app: elasticsearch
    component: storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd

---
# Elasticsearch StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: digital-employee
  labels:
    app: elasticsearch
    component: server
spec:
  serviceName: elasticsearch-svc
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
      component: server
  template:
    metadata:
      labels:
        app: elasticsearch
        component: server
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9114"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: digital-employee-sa
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        runAsNonRoot: true
      initContainers:
      # 初始化容器 - 设置vm.max_map_count
      - name: init-sysctl
        image: busybox:1.35
        imagePullPolicy: IfNotPresent
        command:
        - sh
        - -c
        - |
          sysctl -w vm.max_map_count=262144
          echo "vm.max_map_count set successfully"
        securityContext:
          privileged: true
          runAsUser: 0
          
      # 初始化存储权限
      - name: init-permissions
        image: busybox:1.35
        imagePullPolicy: IfNotPresent
        command:
        - sh
        - -c
        - |
          chown -R 1000:1000 /usr/share/elasticsearch/data
          chmod -R 755 /usr/share/elasticsearch/data
        volumeMounts:
        - name: elasticsearch-storage
          mountPath: /usr/share/elasticsearch/data
        securityContext:
          runAsUser: 0
          runAsGroup: 0
          
      containers:
      # Elasticsearch主容器
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 9200
          name: http
          protocol: TCP
        - containerPort: 9300
          name: transport
          protocol: TCP
        env:
        - name: discovery.type
          value: "single-node"
        - name: ES_JAVA_OPTS
          value: "-Xms2g -Xmx2g"
        - name: xpack.security.enabled
          value: "false"
        - name: xpack.security.enrollment.enabled
          value: "false"
        - name: cluster.name
          value: "digital-employee-logs"
        - name: node.name
          value: "es-node-1"
        - name: bootstrap.memory_lock
          value: "true"
        - name: cluster.initial_master_nodes
          value: "es-node-1"
        - name: action.destructive_requires_name
          value: "true"
        - name: indices.recovery.max_bytes_per_sec
          value: "100mb"
        - name: network.host
          value: "0.0.0.0"
        volumeMounts:
        - name: elasticsearch-storage
          mountPath: /usr/share/elasticsearch/data
        - name: elasticsearch-config
          mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          subPath: elasticsearch.yml
          readOnly: true
        resources:
          requests:
            memory: "3Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
            scheme: HTTP
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /_cluster/health?wait_for_status=yellow
            port: 9200
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          capabilities:
            drop:
            - ALL
            
      # Elasticsearch Exporter
      - name: elasticsearch-exporter
        image: prometheuscommunity/elasticsearch-exporter:v1.5.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 9114
          name: metrics
          protocol: TCP
        args:
        - --es.uri=http://localhost:9200
        - --es.all
        - --es.indices
        - --es.shards
        - --web.listen-address=:9114
        - --web.telemetry-path=/metrics
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
          runAsGroup: 65534
          capabilities:
            drop:
            - ALL
            
      volumes:
      - name: elasticsearch-storage
        persistentVolumeClaim:
          claimName: elasticsearch-pvc
      - name: elasticsearch-config
        configMap:
          name: elasticsearch-config

---
# Elasticsearch服务
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch-svc
  namespace: digital-employee
  labels:
    app: elasticsearch
    component: server
spec:
  type: ClusterIP
  clusterIP: None  # Headless service for StatefulSet
  ports:
  - port: 9200
    targetPort: 9200
    protocol: TCP
    name: http
  - port: 9300
    targetPort: 9300
    protocol: TCP
    name: transport
  - port: 9114
    targetPort: 9114
    protocol: TCP
    name: metrics
  selector:
    app: elasticsearch
    component: server

---
# Elasticsearch内部服务
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: digital-employee
  labels:
    app: elasticsearch
    component: internal
spec:
  type: ClusterIP
  ports:
  - port: 9200
    targetPort: 9200
    protocol: TCP
    name: http
  selector:
    app: elasticsearch
    component: server

---
# Kibana Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: digital-employee
  labels:
    app: kibana
    component: server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
      component: server
  template:
    metadata:
      labels:
        app: kibana
        component: server
    spec:
      serviceAccountName: digital-employee-sa
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        runAsNonRoot: true
      initContainers:
      - name: wait-for-elasticsearch
        image: busybox:1.35
        imagePullPolicy: IfNotPresent
        command:
        - sh
        - -c
        - |
          until wget -q --spider http://elasticsearch:9200/_cluster/health; do
            echo "Waiting for Elasticsearch to be ready..."
            sleep 10
          done
          echo "Elasticsearch is ready!"
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
            
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.9.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 5601
          name: kibana
          protocol: TCP
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch:9200"
        - name: ELASTICSEARCH_USERNAME
          value: "elastic"
        - name: ELASTICSEARCH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: digital-employee-secrets
              key: ELASTIC_PASSWORD
        - name: SERVER_NAME
          value: "kibana"
        - name: SERVER_HOST
          value: "0.0.0.0"
        - name: LOGGING_QUIET
          value: "true"
        volumeMounts:
        - name: kibana-config
          mountPath: /usr/share/kibana/config/kibana.yml
          subPath: kibana.yml
          readOnly: true
        - name: kibana-data
          mountPath: /usr/share/kibana/data
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /api/status
            port: 5601
            scheme: HTTP
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /api/status
            port: 5601
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          capabilities:
            drop:
            - ALL
            
      volumes:
      - name: kibana-config
        configMap:
          name: kibana-config
      - name: kibana-data
        emptyDir:
          sizeLimit: 5Gi

---
# Kibana服务
apiVersion: v1
kind: Service
metadata:
  name: kibana-svc
  namespace: digital-employee
  labels:
    app: kibana
    component: server
spec:
  type: ClusterIP
  ports:
  - port: 5601
    targetPort: 5601
    protocol: TCP
    name: kibana
  selector:
    app: kibana
    component: server

---
# Logstash Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  namespace: digital-employee
  labels:
    app: logstash
    component: server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: logstash
      component: server
  template:
    metadata:
      labels:
        app: logstash
        component: server
    spec:
      serviceAccountName: digital-employee-sa
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        runAsNonRoot: true
      initContainers:
      - name: wait-for-elasticsearch
        image: busybox:1.35
        imagePullPolicy: IfNotPresent
        command:
        - sh
        - -c
        - |
          until wget -q --spider http://elasticsearch:9200/_cluster/health; do
            echo "Waiting for Elasticsearch to be ready..."
            sleep 10
          done
          echo "Elasticsearch is ready!"
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
            
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:8.9.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 5044
          name: beats
          protocol: TCP
        - containerPort: 9600
          name: monitoring
          protocol: TCP
        env:
        - name: LS_JAVA_OPTS
          value: "-Xmx1g -Xms1g"
        - name: PIPELINE_WORKERS
          value: "2"
        - name: PIPELINE_BATCH_SIZE
          value: "125"
        - name: PIPELINE_BATCH_DELAY
          value: "50"
        volumeMounts:
        - name: logstash-config
          mountPath: /usr/share/logstash/pipeline/logstash.conf
          subPath: logstash.conf
          readOnly: true
        - name: logstash-settings
          mountPath: /usr/share/logstash/config/logstash.yml
          subPath: logstash.yml
          readOnly: true
        - name: app-logs
          mountPath: /var/log/digital_employee
          readOnly: true
        - name: nginx-logs
          mountPath: /var/log/nginx
          readOnly: true
        - name: logstash-data
          mountPath: /usr/share/logstash/data
        resources:
          requests:
            memory: "1.5Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /
            port: 9600
            scheme: HTTP
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /
            port: 9600
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          capabilities:
            drop:
            - ALL
            
      volumes:
      - name: logstash-config
        configMap:
          name: logstash-config
      - name: logstash-settings
        configMap:
          name: logstash-settings
      - name: app-logs
        persistentVolumeClaim:
          claimName: digital-employee-logs-pvc
      - name: nginx-logs
        persistentVolumeClaim:
          claimName: nginx-logs-pvc
      - name: logstash-data
        emptyDir:
          sizeLimit: 2Gi

---
# Logstash服务
apiVersion: v1
kind: Service
metadata:
  name: logstash-svc
  namespace: digital-employee
  labels:
    app: logstash
    component: server
spec:
  type: ClusterIP
  ports:
  - port: 5044
    targetPort: 5044
    protocol: TCP
    name: beats
  - port: 9600
    targetPort: 9600
    protocol: TCP
    name: monitoring
  selector:
    app: logstash
    component: server

---
# Elasticsearch配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: elasticsearch-config
  namespace: digital-employee
  labels:
    app: elasticsearch
    component: config
data:
  elasticsearch.yml: |
    # Elasticsearch 8.9 Production Configuration
    
    # Cluster
    cluster.name: digital-employee-logs
    node.name: es-node-1
    
    # Network
    network.host: 0.0.0.0
    http.port: 9200
    transport.port: 9300
    
    # Discovery
    discovery.type: single-node
    cluster.initial_master_nodes: ["es-node-1"]
    
    # Path settings
    path.data: /usr/share/elasticsearch/data
    path.logs: /usr/share/elasticsearch/logs
    
    # Memory
    bootstrap.memory_lock: true
    
    # Security (disabled for simplicity)
    xpack.security.enabled: false
    xpack.security.enrollment.enabled: false
    xpack.security.http.ssl.enabled: false
    xpack.security.transport.ssl.enabled: false
    
    # Monitoring
    xpack.monitoring.collection.enabled: true
    
    # Index settings
    action.destructive_requires_name: true
    
    # Performance settings
    indices.recovery.max_bytes_per_sec: 100mb
    cluster.routing.allocation.disk.threshold_enabled: true
    cluster.routing.allocation.disk.watermark.low: 85%
    cluster.routing.allocation.disk.watermark.high: 90%
    cluster.routing.allocation.disk.watermark.flood_stage: 95%
    
    # Logging
    logger.org.elasticsearch.deprecation: warn

---
# Kibana配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: kibana-config
  namespace: digital-employee
  labels:
    app: kibana
    component: config
data:
  kibana.yml: |
    # Kibana 8.9 Production Configuration
    
    # Server
    server.name: kibana
    server.host: 0.0.0.0
    server.port: 5601
    server.basePath: ""
    server.publicBaseUrl: ""
    
    # Elasticsearch
    elasticsearch.hosts: ["http://elasticsearch:9200"]
    elasticsearch.username: "elastic"
    elasticsearch.password: "${ELASTICSEARCH_PASSWORD}"
    elasticsearch.requestTimeout: 132000
    elasticsearch.shardTimeout: 30000
    
    # Kibana index
    kibana.index: ".kibana"
    kibana.defaultAppId: "discover"
    
    # Security
    xpack.security.enabled: false
    xpack.encryptedSavedObjects.encryptionKey: "digital-employee-kibana-encryption-key-32-chars"
    
    # Monitoring
    monitoring.ui.container.elasticsearch.enabled: true
    
    # Logging
    logging.quiet: true
    logging.dest: stdout
    logging.json: true
    
    # Performance
    elasticsearch.requestHeadersWhitelist: ["authorization"]
    
    # UI Settings
    newsfeed.enabled: false
    telemetry.enabled: false
    telemetry.optIn: false

---
# Logstash设置配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-settings
  namespace: digital-employee
  labels:
    app: logstash
    component: config
data:
  logstash.yml: |
    # Logstash 8.9 Configuration
    
    # Node
    node.name: logstash-1
    
    # Pipeline
    pipeline.workers: 2
    pipeline.batch.size: 125
    pipeline.batch.delay: 50
    
    # Path settings
    path.data: /usr/share/logstash/data
    path.logs: /usr/share/logstash/logs
    path.settings: /usr/share/logstash/config
    
    # Pipeline configuration
    config.reload.automatic: false
    config.reload.interval: 3s
    
    # HTTP API
    http.host: "0.0.0.0"
    http.port: 9600
    
    # Monitoring
    monitoring.enabled: true
    monitoring.elasticsearch.hosts: ["http://elasticsearch:9200"]
    
    # Logging
    log.level: info
    log.format: json
    
    # Queue settings
    queue.type: memory
    queue.max_events: 0
    queue.max_bytes: 1gb
    
    # Dead letter queue
    dead_letter_queue.enable: true
    dead_letter_queue.max_bytes: 1gb

---
# 扩展的Logstash配置（从之前的ConfigMap继承）
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
  namespace: digital-employee
  labels:
    app: logstash
    component: pipeline
data:
  logstash.conf: |
    input {
      # 从文件读取数字员工应用日志
      file {
        path => "/var/log/digital_employee/*.log"
        start_position => "beginning"
        codec => json
        tags => ["digital_employee", "application"]
        type => "application"
      }
      
      # 从Nginx访问日志读取
      file {
        path => "/var/log/nginx/access.log"
        start_position => "beginning"
        codec => json
        tags => ["nginx", "access"]
        type => "nginx_access"
      }
      
      # 从Nginx错误日志读取
      file {
        path => "/var/log/nginx/error.log"
        start_position => "beginning"
        tags => ["nginx", "error"]
        type => "nginx_error"
      }
      
      # Beats输入（用于扩展）
      beats {
        port => 5044
      }
    }
    
    filter {
      # 添加通用字段
      mutate {
        add_field => { 
          "environment" => "production"
          "cluster" => "digital-employee-k8s"
          "parsed_at" => "%{@timestamp}"
        }
      }
      
      # 处理数字员工应用日志
      if "digital_employee" in [tags] {
        mutate {
          add_field => { "service" => "digital-employee" }
        }
        
        # 解析时间戳
        if [timestamp] {
          date {
            match => [ "timestamp", "ISO8601" ]
            target => "@timestamp"
          }
        }
        
        # 提取和标准化日志级别
        if [level] {
          mutate {
            add_field => { "log_level" => "%{level}" }
            lowercase => [ "log_level" ]
          }
        }
        
        # 解析Agent信息
        if [agent_id] {
          mutate {
            add_field => { "agent" => "%{agent_id}" }
          }
        }
        
        # 提取性能指标
        if [response_time] {
          mutate {
            convert => { "response_time" => "float" }
          }
        }
        
        if [memory_usage] {
          mutate {
            convert => { "memory_usage" => "float" }
          }
        }
      }
      
      # 处理Nginx访问日志
      if "nginx" in [tags] and "access" in [tags] {
        mutate {
          add_field => { "service" => "nginx" }
        }
        
        # Nginx访问日志已经是JSON格式
        if [status] {
          mutate {
            convert => { "status" => "integer" }
          }
        }
        
        if [body_bytes_sent] {
          mutate {
            convert => { "body_bytes_sent" => "integer" }
          }
        }
        
        if [request_time] {
          mutate {
            convert => { "request_time" => "float" }
          }
        }
        
        # 解析HTTP方法和路径
        if [request] {
          grok {
            match => { "request" => "%{WORD:method} %{URIPATH:path}(?:%{URIPARAM:params})? HTTP/%{NUMBER:http_version}" }
          }
        }
        
        # 分类HTTP状态码
        if [status] {
          if [status] >= 200 and [status] < 300 {
            mutate { add_field => { "status_category" => "success" } }
          } else if [status] >= 300 and [status] < 400 {
            mutate { add_field => { "status_category" => "redirect" } }
          } else if [status] >= 400 and [status] < 500 {
            mutate { add_field => { "status_category" => "client_error" } }
          } else if [status] >= 500 {
            mutate { add_field => { "status_category" => "server_error" } }
          }
        }
      }
      
      # 处理Nginx错误日志
      if "nginx" in [tags] and "error" in [tags] {
        mutate {
          add_field => { "service" => "nginx" }
        }
        
        # 解析错误日志格式
        grok {
          match => { "message" => "%{DATESTAMP:timestamp} \[%{WORD:log_level}\] %{POSINT:pid}#%{POSINT:tid}: \*%{POSINT:connection_id} %{GREEDYDATA:error_message}" }
        }
        
        # 转换时间戳
        if [timestamp] {
          date {
            match => [ "timestamp", "yyyy/MM/dd HH:mm:ss" ]
            target => "@timestamp"
          }
        }
      }
      
      # GeoIP解析（如果有外部访问）
      if [remote_addr] and [remote_addr] !~ /^10\./ and [remote_addr] !~ /^192\.168\./ and [remote_addr] !~ /^172\./ {
        geoip {
          source => "remote_addr"
          target => "geoip"
        }
      }
      
      # 移除不需要的字段
      mutate {
        remove_field => [ "host", "path", "@version" ]
      }
    }
    
    output {
      # 输出到Elasticsearch
      elasticsearch {
        hosts => ["elasticsearch:9200"]
        
        # 基于日志类型创建不同的索引
        if "digital_employee" in [tags] {
          index => "digital-employee-app-%{+YYYY.MM.dd}"
        } else if "nginx" in [tags] and "access" in [tags] {
          index => "nginx-access-%{+YYYY.MM.dd}"
        } else if "nginx" in [tags] and "error" in [tags] {
          index => "nginx-error-%{+YYYY.MM.dd}"
        } else {
          index => "digital-employee-other-%{+YYYY.MM.dd}"
        }
        
        # 模板配置
        template_name => "digital-employee"
        template_pattern => "digital-employee-*"
        template => "/usr/share/logstash/templates/digital-employee-template.json"
        template_overwrite => true
        
        # 性能优化
        workers => 2
        flush_size => 500
        idle_flush_time => 1
      }
      
      # 调试输出（生产环境可以关闭）
      if [log_level] == "debug" {
        stdout {
          codec => json_lines
        }
      }
    }