# æ•°å­—å‘˜å·¥ç³»ç»Ÿå¼€å‘è§„èŒƒ

## ğŸ¯ æ€»ä½“åŸåˆ™

### æ ¸å¿ƒç†å¿µ
- **åŠ¡å®ä¼˜å…ˆ**ï¼šè§£å†³å®é™…é—®é¢˜ï¼Œé¿å…è¿‡åº¦è®¾è®¡
- **æ•°æ®é©±åŠ¨**ï¼šåŸºäºä½¿ç”¨æ•°æ®åšå†³ç­–ï¼Œè€Œéå‡è®¾
- **æ¸è¿›æ¼”è¿›**ï¼šå°æ­¥å¿«è·‘ï¼ŒæŒç»­æ”¹è¿›
- **è´¨é‡å†…ç”Ÿ**ï¼šä»£ç å³æ–‡æ¡£ï¼Œæµ‹è¯•é©±åŠ¨å¼€å‘

### æ¶æ„åŸåˆ™ (SOLID+)
1. **S - å•ä¸€èŒè´£**ï¼šæ¯ä¸ªç±»/å‡½æ•°åªåšä¸€ä»¶äº‹
2. **O - å¼€é—­åŸåˆ™**ï¼šå¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å…³é—­
3. **L - é‡Œæ°æ›¿æ¢**ï¼šå­ç±»å¯ä»¥æ›¿æ¢çˆ¶ç±»
4. **I - æ¥å£éš”ç¦»**ï¼šå°è€Œä¸“çš„æ¥å£è®¾è®¡
5. **D - ä¾èµ–å€’ç½®**ï¼šä¾èµ–æŠ½è±¡ï¼Œä¸ä¾èµ–å…·ä½“
6. **+ æ•°æ®é©±åŠ¨**ï¼šåŸºäºç›‘æ§æ•°æ®åšä¼˜åŒ–å†³ç­–
7. **+ AIä¼˜å…ˆ**ï¼šä¼˜å…ˆè€ƒè™‘AIè§£å†³æ–¹æ¡ˆçš„å¯èƒ½æ€§

---

## ğŸ“ é¡¹ç›®ç»“æ„è§„èŒƒ

### æ ‡å‡†é¡¹ç›®ç»“æ„
```
digital_employee/
â”œâ”€â”€ core/                    # æ ¸å¿ƒåŸºç¡€ç»„ä»¶
â”‚   â”œâ”€â”€ agent_base.py       # AgentåŸºç¡€æŠ½è±¡ç±»
â”‚   â”œâ”€â”€ ai_service.py       # AIæœåŠ¡æŠ½è±¡å±‚
â”‚   â”œâ”€â”€ config.py           # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ database.py         # æ•°æ®åº“è¿æ¥ç®¡ç†
â”‚   â”œâ”€â”€ exceptions.py       # è‡ªå®šä¹‰å¼‚å¸¸
â”‚   â””â”€â”€ monitoring.py       # ç›‘æ§å’ŒæŒ‡æ ‡
â”œâ”€â”€ agents/                  # Agentå®ç°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unified_agent.py    # ç»Ÿä¸€Agentå®ç°
â”‚   â””â”€â”€ specialized/        # ä¸“ä¸šåŒ–Agentï¼ˆæŒ‰éœ€æ·»åŠ ï¼‰
â”‚       â”œâ”€â”€ requirement_analysis.py
â”‚       â”œâ”€â”€ architecture_design.py
â”‚       â””â”€â”€ code_generation.py
â”œâ”€â”€ api/                     # APIæ¥å£å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py             # ä¸»APIåº”ç”¨
â”‚   â”œâ”€â”€ routes/             # è·¯ç”±æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ tasks.py
â”‚   â”‚   â””â”€â”€ system.py
â”‚   â”œâ”€â”€ models/             # Pydanticæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ requests.py
â”‚   â”‚   â””â”€â”€ responses.py
â”‚   â””â”€â”€ middleware/         # ä¸­é—´ä»¶
â”‚       â”œâ”€â”€ auth.py
â”‚       â”œâ”€â”€ cors.py
â”‚       â””â”€â”€ monitoring.py
â”œâ”€â”€ services/                # ä¸šåŠ¡æœåŠ¡å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ task_service.py     # ä»»åŠ¡å¤„ç†æœåŠ¡
â”‚   â”œâ”€â”€ cache_service.py    # ç¼“å­˜æœåŠ¡
â”‚   â””â”€â”€ notification_service.py # é€šçŸ¥æœåŠ¡
â”œâ”€â”€ models/                  # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ task.py             # ä»»åŠ¡æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ agent.py            # Agentæ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ user.py             # ç”¨æˆ·æ•°æ®æ¨¡å‹
â”œâ”€â”€ utils/                   # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py           # æ—¥å¿—å·¥å…·
â”‚   â”œâ”€â”€ validators.py       # éªŒè¯å·¥å…·
â”‚   â””â”€â”€ helpers.py          # é€šç”¨å·¥å…·
â””â”€â”€ tests/                   # æµ‹è¯•ç›®å½•
    â”œâ”€â”€ unit/               # å•å…ƒæµ‹è¯•
    â”œâ”€â”€ integration/        # é›†æˆæµ‹è¯•
    â””â”€â”€ fixtures/           # æµ‹è¯•æ•°æ®
```

### æ–‡ä»¶å‘½åè§„èŒƒ
- **Pythonæ–‡ä»¶**ï¼šä½¿ç”¨snake_caseï¼ˆå¦‚ï¼š`ai_service.py`ï¼‰
- **ç±»å**ï¼šä½¿ç”¨PascalCaseï¼ˆå¦‚ï¼š`AIService`ï¼‰
- **å‡½æ•°/å˜é‡**ï¼šä½¿ç”¨snake_caseï¼ˆå¦‚ï¼š`process_task`ï¼‰
- **å¸¸é‡**ï¼šä½¿ç”¨UPPER_SNAKE_CASEï¼ˆå¦‚ï¼š`MAX_RETRY_COUNT`ï¼‰
- **ç¯å¢ƒå˜é‡**ï¼šä½¿ç”¨UPPER_SNAKE_CASEï¼ˆå¦‚ï¼š`OPENAI_API_KEY`ï¼‰

---

## ğŸ¤– AIæœåŠ¡å¼€å‘è§„èŒƒ

### AIæœåŠ¡æŠ½è±¡å±‚è®¾è®¡
```python
# digital_employee/core/ai_service.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import asyncio
import logging

@dataclass
class AIRequest:
    """AIæœåŠ¡è¯·æ±‚æ ‡å‡†æ ¼å¼"""
    prompt: str
    system_prompt: Optional[str] = None
    context: Optional[Dict[str, Any]] = None
    temperature: float = 0.7
    max_tokens: Optional[int] = None
    model: Optional[str] = None

@dataclass  
class AIResponse:
    """AIæœåŠ¡å“åº”æ ‡å‡†æ ¼å¼"""
    content: str
    usage: Dict[str, int]
    model: str
    confidence_score: Optional[float] = None
    finish_reason: Optional[str] = None

class AIService(ABC):
    """AIæœåŠ¡æŠ½è±¡åŸºç±» - ç»Ÿä¸€ä¸åŒAIå‚å•†çš„æ¥å£"""
    
    @abstractmethod
    async def generate_response(self, request: AIRequest) -> AIResponse:
        """ç”ŸæˆAIå“åº”"""
        pass
    
    @abstractmethod
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        pass
    
    @abstractmethod
    def get_supported_models(self) -> List[str]:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        pass
```

### AIæœåŠ¡å®ç°è§„èŒƒ
```python
class OpenAIService(AIService):
    """OpenAIæœåŠ¡å®ç°"""
    
    def __init__(self, api_key: str, default_model: str = "gpt-4"):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.default_model = default_model
        self.logger = logging.getLogger(__name__)
        
        # é‡è¯•é…ç½®
        self.max_retries = 3
        self.retry_delay = 1.0
        
        # ç›‘æ§æŒ‡æ ‡
        self.request_count = 0
        self.error_count = 0
        self.total_tokens_used = 0
    
    async def generate_response(self, request: AIRequest) -> AIResponse:
        """ç”Ÿæˆå“åº” - åŒ…å«é‡è¯•ã€ç›‘æ§ã€é”™è¯¯å¤„ç†"""
        self.request_count += 1
        
        for attempt in range(self.max_retries):
            try:
                response = await self._make_request(request)
                self.total_tokens_used += response.usage.get('total_tokens', 0)
                return response
                
            except openai.RateLimitError:
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay * (2 ** attempt))
                    continue
                raise
                
            except Exception as e:
                self.error_count += 1
                self.logger.error(f"AI service error: {e}")
                if attempt == self.max_retries - 1:
                    raise
                await asyncio.sleep(self.retry_delay)
        
        raise Exception("Max retries exceeded")
    
    async def _make_request(self, request: AIRequest) -> AIResponse:
        """å®é™…çš„APIè°ƒç”¨"""
        messages = []
        if request.system_prompt:
            messages.append({"role": "system", "content": request.system_prompt})
        messages.append({"role": "user", "content": request.prompt})
        
        response = await self.client.chat.completions.create(
            model=request.model or self.default_model,
            messages=messages,
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        
        return AIResponse(
            content=response.choices[0].message.content,
            usage=response.usage.model_dump(),
            model=response.model,
            finish_reason=response.choices[0].finish_reason
        )
```

---

## ğŸ”§ Agentå¼€å‘è§„èŒƒ

### AgentåŸºç±»è§„èŒƒ
```python
# ç»§æ‰¿ç°æœ‰BaseAgentï¼Œæ·»åŠ AIèƒ½åŠ›
class AIEnhancedAgent(BaseAgent):
    """AIå¢å¼ºçš„AgentåŸºç±»"""
    
    def __init__(self, name: str, ai_service: AIService):
        super().__init__(name)
        self.ai_service = ai_service
        self.system_prompts = self._load_system_prompts()
        
        # æ€§èƒ½ç›‘æ§
        self.ai_request_count = 0
        self.ai_error_count = 0
        self.avg_ai_response_time = 0.0
    
    def _load_system_prompts(self) -> Dict[str, str]:
        """åŠ è½½ç³»ç»Ÿæç¤ºè¯ - ä»é…ç½®æ–‡ä»¶åŠ è½½"""
        return {
            "default": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚æä¾›å‡†ç¡®çš„å¸®åŠ©ã€‚",
            "requirement_analysis": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ä¸šåŠ¡éœ€æ±‚åˆ†æå¸ˆ...",
            "code_generation": "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„è½¯ä»¶å·¥ç¨‹å¸ˆ..."
        }
    
    async def _call_ai_service(self, 
                              prompt: str, 
                              prompt_type: str = "default",
                              context: Optional[Dict[str, Any]] = None) -> str:
        """ç»Ÿä¸€çš„AIæœåŠ¡è°ƒç”¨æ–¹æ³•"""
        import time
        start_time = time.time()
        
        try:
            self.ai_request_count += 1
            
            request = AIRequest(
                prompt=prompt,
                system_prompt=self.system_prompts.get(prompt_type),
                context=context
            )
            
            response = await self.ai_service.generate_response(request)
            
            # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            response_time = time.time() - start_time
            self.avg_ai_response_time = (
                (self.avg_ai_response_time * (self.ai_request_count - 1) + response_time) 
                / self.ai_request_count
            )
            
            return response.content
            
        except Exception as e:
            self.ai_error_count += 1
            self.logger.error(f"AI service call failed: {e}")
            raise
```

### Agentå®ç°è§„èŒƒ
```python
class UnifiedDigitalEmployee(AIEnhancedAgent):
    """AIå¢å¼ºçš„ç»Ÿä¸€æ•°å­—å‘˜å·¥"""
    
    def __init__(self, ai_service: AIService):
        super().__init__("UnifiedDigitalEmployee", ai_service)
        self.supported_tasks = {
            TaskType.REQUIREMENT_ANALYSIS,
            TaskType.SOLUTION_DESIGN,
            TaskType.CODE_GENERATION,
            TaskType.PROJECT_PLANNING,
            TaskType.GENERAL_INQUIRY
        }
    
    async def _analyze_requirement(self, user_input: str) -> Dict[str, Any]:
        """éœ€æ±‚åˆ†æ - AIé©±åŠ¨å®ç°"""
        
        # 1. æ„å»ºä¸“ä¸šåŒ–æç¤ºè¯
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·éœ€æ±‚ï¼Œæä¾›ç»“æ„åŒ–åˆ†æï¼š

        ç”¨æˆ·éœ€æ±‚ï¼š{user_input}

        è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
        {{
            "functional_requirements": ["éœ€æ±‚1", "éœ€æ±‚2"],
            "non_functional_requirements": ["æ€§èƒ½è¦æ±‚", "å®‰å…¨è¦æ±‚"],
            "clarification_questions": ["é—®é¢˜1", "é—®é¢˜2"],
            "ears_format": ["The system shall...", "The system shall..."],
            "confidence_score": 0.85,
            "risk_assessment": "ä½/ä¸­/é«˜",
            "estimated_complexity": "ç®€å•/ä¸­ç­‰/å¤æ‚"
        }}
        """
        
        # 2. è°ƒç”¨AIæœåŠ¡
        try:
            ai_response = await self._call_ai_service(
                prompt, 
                "requirement_analysis",
                {"user_input": user_input}
            )
            
            # 3. è§£æå’ŒéªŒè¯AIå“åº”
            result = self._parse_and_validate_response(ai_response, "requirement_analysis")
            
            # 4. æ·»åŠ é»˜è®¤å€¼å’Œåå¤„ç†
            result.setdefault("confidence_score", 0.8)
            result.setdefault("processing_metadata", {
                "ai_model_used": self.ai_service.__class__.__name__,
                "processing_time": time.time(),
                "agent_version": self.get_version()
            })
            
            return result
            
        except Exception as e:
            # 5. ä¼˜é›…é™çº§ - å›é€€åˆ°è§„åˆ™é€»è¾‘
            self.logger.warning(f"AI analysis failed, falling back to rules: {e}")
            return await self._fallback_requirement_analysis(user_input)
    
    def _parse_and_validate_response(self, ai_response: str, task_type: str) -> Dict[str, Any]:
        """è§£æå’ŒéªŒè¯AIå“åº”"""
        try:
            import json
            result = json.loads(ai_response)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = self._get_required_fields(task_type)
            for field in required_fields:
                if field not in result:
                    raise ValueError(f"Missing required field: {field}")
            
            return result
            
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°è¯•æå–ç»“æ„åŒ–ä¿¡æ¯
            return self._extract_structured_info(ai_response, task_type)
    
    async def _fallback_requirement_analysis(self, user_input: str) -> Dict[str, Any]:
        """é™çº§é€»è¾‘ - ä¿æŒç³»ç»Ÿå¯ç”¨æ€§"""
        # ä½¿ç”¨åŸæœ‰çš„è§„åˆ™é€»è¾‘ä½œä¸ºåå¤‡
        # è¿™é‡Œå¯ä»¥å¤ç”¨åŸæ¥çš„ç¡¬ç¼–ç é€»è¾‘
        return {
            "functional_requirements": ["åŸºç¡€åŠŸèƒ½éœ€æ±‚ï¼ˆè§„åˆ™æå–ï¼‰"],
            "non_functional_requirements": ["åŸºç¡€æ€§èƒ½è¦æ±‚"],
            "clarification_questions": self._generate_default_questions(),
            "confidence_score": 0.6,  # é™çº§é€»è¾‘ç½®ä¿¡åº¦è¾ƒä½
            "fallback_used": True
        }
```

---

## ğŸŒ APIè®¾è®¡è§„èŒƒ

### RESTful APIè§„èŒƒ
```python
# ç»Ÿä¸€çš„APIå“åº”æ ¼å¼
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
from datetime import datetime

class APIResponse(BaseModel):
    """ç»Ÿä¸€APIå“åº”æ ¼å¼"""
    success: bool
    data: Optional[Dict[str, Any]] = None
    message: Optional[str] = None
    error_code: Optional[str] = None
    timestamp: datetime = datetime.now()
    request_id: Optional[str] = None

class PaginatedResponse(APIResponse):
    """åˆ†é¡µå“åº”æ ¼å¼"""
    total: int
    page: int
    per_page: int
    pages: int

# APIè·¯ç”±è§„èŒƒ
@app.post("/api/v1/tasks", response_model=APIResponse)
async def create_task(
    request: TaskRequest,
    request_id: str = Header(None, alias="X-Request-ID"),
    background_tasks: BackgroundTasks = BackgroundTasks()
) -> APIResponse:
    """
    åˆ›å»ºä»»åŠ¡æ¥å£
    
    - ç»Ÿä¸€é”™è¯¯å¤„ç†
    - è¯·æ±‚IDè¿½è¸ª
    - åå°ä»»åŠ¡å¤„ç†
    - æ ‡å‡†å“åº”æ ¼å¼
    """
    try:
        # 1. è¯·æ±‚éªŒè¯
        validated_request = validate_task_request(request)
        
        # 2. ç”Ÿæˆä»»åŠ¡ID
        task_id = generate_task_id()
        
        # 3. å¼‚æ­¥å¤„ç†
        background_tasks.add_task(process_task_async, task_id, validated_request)
        
        # 4. è¿”å›æ ‡å‡†å“åº”
        return APIResponse(
            success=True,
            data={"task_id": task_id, "status": "processing"},
            message="ä»»åŠ¡åˆ›å»ºæˆåŠŸ",
            request_id=request_id
        )
        
    except ValidationError as e:
        return APIResponse(
            success=False,
            message="è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
            error_code="VALIDATION_ERROR",
            request_id=request_id
        )
    except Exception as e:
        logger.error(f"Task creation failed: {e}", extra={"request_id": request_id})
        return APIResponse(
            success=False,
            message="æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
            error_code="INTERNAL_ERROR",
            request_id=request_id
        )
```

### APIç‰ˆæœ¬ç®¡ç†
```python
# ç‰ˆæœ¬è·¯ç”±è®¾è®¡
@app.include_router(v1_router, prefix="/api/v1")
@app.include_router(v2_router, prefix="/api/v2")  # æœªæ¥ç‰ˆæœ¬

# ç‰ˆæœ¬å…¼å®¹æ€§å¤„ç†
class APIVersionMiddleware:
    def __init__(self, app):
        self.app = app
    
    async def __call__(self, scope, receive, send):
        if scope["type"] == "http":
            # æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§
            headers = dict(scope.get("headers", []))
            api_version = headers.get(b"x-api-version", b"v1").decode()
            
            # ç‰ˆæœ¬åºŸå¼ƒè­¦å‘Š
            if api_version == "v1" and self.is_deprecated("v1"):
                # æ·»åŠ åºŸå¼ƒè­¦å‘Šå¤´
                pass
        
        await self.app(scope, receive, send)
```

---

## ğŸ—„ï¸ æ•°æ®åº“è®¾è®¡è§„èŒƒ

### è¡¨è®¾è®¡è§„èŒƒ
```sql
-- æ ‡å‡†å‘½åçº¦å®š
-- è¡¨åï¼šsnake_caseï¼Œå¤æ•°å½¢å¼
-- å­—æ®µåï¼šsnake_case
-- ä¸»é”®ï¼šid (UUID)
-- å¤–é”®ï¼š{table_name}_id
-- æ—¶é—´æˆ³ï¼šcreated_at, updated_at

-- ä»»åŠ¡è¡¨ - æ ¸å¿ƒä¸šåŠ¡è¡¨
CREATE TABLE tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    task_type VARCHAR(50) NOT NULL,
    user_input TEXT NOT NULL,
    context JSONB DEFAULT '{}',
    
    -- çŠ¶æ€ç®¡ç†
    status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
    priority INTEGER DEFAULT 5 CHECK (priority BETWEEN 1 AND 10),
    
    -- ç»“æœæ•°æ®
    result JSONB,
    confidence_score DECIMAL(3,2) CHECK (confidence_score BETWEEN 0.0 AND 1.0),
    processing_time DECIMAL(10,3),
    error_message TEXT,
    
    -- AIæœåŠ¡ä¿¡æ¯
    ai_model_used VARCHAR(100),
    ai_tokens_used INTEGER,
    ai_cost DECIMAL(10,4),
    
    -- å®¡è®¡å­—æ®µ
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    completed_at TIMESTAMP WITH TIME ZONE,
    
    -- ç´¢å¼•ä¼˜åŒ–
    CONSTRAINT valid_completed_status CHECK (
        (status = 'completed' AND completed_at IS NOT NULL) OR 
        (status != 'completed' AND completed_at IS NULL)
    )
);

-- ç´¢å¼•è®¾è®¡
CREATE INDEX idx_tasks_status_created ON tasks(status, created_at);
CREATE INDEX idx_tasks_type_priority ON tasks(task_type, priority);
CREATE INDEX idx_tasks_completed_at ON tasks(completed_at) WHERE completed_at IS NOT NULL;

-- åˆ†åŒºè®¾è®¡ï¼ˆå¯é€‰ - å¤§æ•°æ®é‡æ—¶ï¼‰
CREATE TABLE tasks_2025_01 PARTITION OF tasks 
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

### ORMæ¨¡å‹è§„èŒƒ
```python
# models/task.py
from sqlalchemy import Column, String, Text, Integer, DECIMAL, DateTime, JSON
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid

Base = declarative_base()

class Task(Base):
    """ä»»åŠ¡æ•°æ®æ¨¡å‹"""
    __tablename__ = "tasks"
    
    # ä¸»é”®
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    
    # ä¸šåŠ¡å­—æ®µ
    task_type = Column(String(50), nullable=False, index=True)
    user_input = Column(Text, nullable=False)
    context = Column(JSON, default=dict)
    
    # çŠ¶æ€å­—æ®µ
    status = Column(String(20), default="pending", index=True)
    priority = Column(Integer, default=5)
    
    # ç»“æœå­—æ®µ
    result = Column(JSON)
    confidence_score = Column(DECIMAL(3, 2))
    processing_time = Column(DECIMAL(10, 3))
    error_message = Column(Text)
    
    # AIæœåŠ¡å­—æ®µ
    ai_model_used = Column(String(100))
    ai_tokens_used = Column(Integer)
    ai_cost = Column(DECIMAL(10, 4))
    
    # å®¡è®¡å­—æ®µ
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    completed_at = Column(DateTime(timezone=True))
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "id": str(self.id),
            "task_type": self.task_type,
            "status": self.status,
            "confidence_score": float(self.confidence_score) if self.confidence_score else None,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "completed_at": self.completed_at.isoformat() if self.completed_at else None
        }
    
    @classmethod
    def create_from_request(cls, task_request: TaskRequest) -> "Task":
        """ä»è¯·æ±‚åˆ›å»ºä»»åŠ¡å®ä¾‹"""
        return cls(
            task_type=task_request.task_type.value,
            user_input=task_request.user_input,
            context=task_request.context or {},
            priority=task_request.priority
        )
```

---

## ğŸ›¡ï¸ é”™è¯¯å¤„ç†è§„èŒƒ

### å¼‚å¸¸å±‚æ¬¡è®¾è®¡
```python
# core/exceptions.py
class DigitalEmployeeException(Exception):
    """ç³»ç»ŸåŸºç¡€å¼‚å¸¸ç±»"""
    def __init__(self, message: str, error_code: str = None, details: Dict = None):
        self.message = message
        self.error_code = error_code or "UNKNOWN_ERROR"
        self.details = details or {}
        super().__init__(self.message)

class ValidationError(DigitalEmployeeException):
    """æ•°æ®éªŒè¯å¼‚å¸¸"""
    def __init__(self, message: str, field: str = None):
        super().__init__(message, "VALIDATION_ERROR", {"field": field})

class AIServiceError(DigitalEmployeeException):
    """AIæœåŠ¡å¼‚å¸¸"""
    def __init__(self, message: str, service_name: str, original_error: Exception = None):
        super().__init__(
            message, 
            "AI_SERVICE_ERROR", 
            {
                "service": service_name,
                "original_error": str(original_error) if original_error else None
            }
        )

class TaskProcessingError(DigitalEmployeeException):
    """ä»»åŠ¡å¤„ç†å¼‚å¸¸"""
    def __init__(self, message: str, task_id: str, task_type: str):
        super().__init__(
            message,
            "TASK_PROCESSING_ERROR",
            {"task_id": task_id, "task_type": task_type}
        )

# å¼‚å¸¸å¤„ç†ä¸­é—´ä»¶
class ExceptionHandlingMiddleware:
    def __init__(self, app):
        self.app = app
    
    async def __call__(self, scope, receive, send):
        try:
            await self.app(scope, receive, send)
        except DigitalEmployeeException as e:
            # ä¸šåŠ¡å¼‚å¸¸å¤„ç†
            response = self._create_error_response(e)
            await self._send_json_response(response, send)
        except Exception as e:
            # æœªé¢„æœŸå¼‚å¸¸å¤„ç†
            logger.error(f"Unhandled exception: {e}", exc_info=True)
            response = self._create_generic_error_response()
            await self._send_json_response(response, send)
```

---

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—è§„èŒƒ

### æ—¥å¿—è§„èŒƒ
```python
# utils/logger.py
import logging
import json
from datetime import datetime
from typing import Dict, Any

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—å™¨"""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        # æ·»åŠ ç»“æ„åŒ–å¤„ç†å™¨
        handler = logging.StreamHandler()
        formatter = StructuredFormatter()
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
    
    def info(self, message: str, **kwargs):
        self._log(logging.INFO, message, kwargs)
    
    def error(self, message: str, **kwargs):
        self._log(logging.ERROR, message, kwargs)
    
    def _log(self, level: int, message: str, extra: Dict[str, Any]):
        """è®°å½•ç»“æ„åŒ–æ—¥å¿—"""
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": logging.getLevelName(level),
            "message": message,
            "service": "digital_employee",
            **extra
        }
        self.logger.log(level, json.dumps(log_data))

class StructuredFormatter(logging.Formatter):
    """ç»“æ„åŒ–æ—¥å¿—æ ¼å¼å™¨"""
    
    def format(self, record):
        if hasattr(record, 'extra'):
            return record.getMessage()
        return super().format(record)
```

### ç›‘æ§æŒ‡æ ‡è§„èŒƒ
```python
# core/monitoring.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time
from functools import wraps

# å®šä¹‰ç›‘æ§æŒ‡æ ‡
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')
ACTIVE_TASKS = Gauge('active_tasks_total', 'Number of active tasks')
AI_REQUEST_COUNT = Counter('ai_requests_total', 'Total AI service requests', ['service', 'status'])
AI_TOKEN_USAGE = Counter('ai_tokens_used_total', 'Total AI tokens used', ['service', 'model'])

def monitor_api_call(func):
    """APIè°ƒç”¨ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            REQUEST_COUNT.labels(method='POST', endpoint=func.__name__, status='success').inc()
            return result
        except Exception as e:
            REQUEST_COUNT.labels(method='POST', endpoint=func.__name__, status='error').inc()
            raise
        finally:
            REQUEST_DURATION.observe(time.time() - start_time)
    return wrapper

def monitor_ai_call(service_name: str):
    """AIæœåŠ¡è°ƒç”¨ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            try:
                result = await func(*args, **kwargs)
                AI_REQUEST_COUNT.labels(service=service_name, status='success').inc()
                if hasattr(result, 'usage'):
                    tokens = result.usage.get('total_tokens', 0)
                    AI_TOKEN_USAGE.labels(service=service_name, model=result.model).inc(tokens)
                return result
            except Exception as e:
                AI_REQUEST_COUNT.labels(service=service_name, status='error').inc()
                raise
        return wrapper
    return decorator
```

---

## âœ… æµ‹è¯•è§„èŒƒ

### æµ‹è¯•åˆ†å±‚ç­–ç•¥
```python
# tests/unit/test_ai_service.py
import pytest
from unittest.mock import AsyncMock, patch
from digital_employee.core.ai_service import OpenAIService, AIRequest

class TestOpenAIService:
    """AIæœåŠ¡å•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    def ai_service(self):
        return OpenAIService(api_key="test-key")
    
    @pytest.mark.asyncio
    async def test_generate_response_success(self, ai_service):
        """æµ‹è¯•æˆåŠŸå“åº”ç”Ÿæˆ"""
        # Arrange
        request = AIRequest(prompt="Test prompt", system_prompt="Test system")
        
        with patch.object(ai_service, '_make_request') as mock_request:
            mock_request.return_value = AsyncMock()
            mock_request.return_value.content = "Test response"
            
            # Act
            response = await ai_service.generate_response(request)
            
            # Assert
            assert response.content == "Test response"
            mock_request.assert_called_once_with(request)
    
    @pytest.mark.asyncio
    async def test_generate_response_with_retry(self, ai_service):
        """æµ‹è¯•é‡è¯•æœºåˆ¶"""
        request = AIRequest(prompt="Test prompt")
        
        with patch.object(ai_service, '_make_request') as mock_request:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨å¤±è´¥ï¼Œç¬¬äºŒæ¬¡æˆåŠŸ
            mock_request.side_effect = [Exception("API Error"), AsyncMock()]
            mock_request.return_value.content = "Success after retry"
            
            response = await ai_service.generate_response(request)
            
            assert response.content == "Success after retry"
            assert mock_request.call_count == 2

# tests/integration/test_task_processing.py
class TestTaskProcessing:
    """ä»»åŠ¡å¤„ç†é›†æˆæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_end_to_end_task_processing(self, test_client, mock_ai_service):
        """ç«¯åˆ°ç«¯ä»»åŠ¡å¤„ç†æµ‹è¯•"""
        # æ¨¡æ‹Ÿå®Œæ•´çš„ä»»åŠ¡å¤„ç†æµç¨‹
        task_request = {
            "task_type": "requirement_analysis",
            "user_input": "I need a user management system"
        }
        
        response = await test_client.post("/api/v1/tasks", json=task_request)
        assert response.status_code == 200
        
        task_id = response.json()["data"]["task_id"]
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await self._wait_for_task_completion(test_client, task_id)
        
        # éªŒè¯ç»“æœ
        result = await test_client.get(f"/api/v1/tasks/{task_id}")
        assert result.json()["data"]["status"] == "completed"
```

### æ€§èƒ½æµ‹è¯•è§„èŒƒ
```python
# tests/performance/test_load.py
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor

class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self, test_client):
        """å¹¶å‘è¯·æ±‚æµ‹è¯•"""
        concurrent_requests = 50
        request_data = {
            "task_type": "general_inquiry",
            "user_input": "What is the weather today?"
        }
        
        async def make_request():
            return await test_client.post("/api/v1/tasks", json=request_data)
        
        start_time = time.time()
        
        # å¹¶å‘æ‰§è¡Œè¯·æ±‚
        tasks = [make_request() for _ in range(concurrent_requests)]
        responses = await asyncio.gather(*tasks)
        
        end_time = time.time()
        
        # æ–­è¨€
        assert all(r.status_code == 200 for r in responses)
        assert end_time - start_time < 30  # 50ä¸ªè¯·æ±‚åº”åœ¨30ç§’å†…å®Œæˆ
        
    def test_memory_usage(self):
        """å†…å­˜ä½¿ç”¨æµ‹è¯•"""
        # ä½¿ç”¨memory_profileræˆ–ç±»ä¼¼å·¥å…·æµ‹è¯•å†…å­˜ä½¿ç”¨
        pass
```

---

## ğŸ“‹ ä»£ç è´¨é‡æ£€æŸ¥æ¸…å•

### æäº¤å‰æ£€æŸ¥æ¸…å•
- [ ] **ä»£ç æ ¼å¼åŒ–**ï¼šä½¿ç”¨blackå’Œisortæ ¼å¼åŒ–ä»£ç 
- [ ] **é™æ€åˆ†æ**ï¼šé€šè¿‡mypyç±»å‹æ£€æŸ¥
- [ ] **ä»£ç è´¨é‡**ï¼šé€šè¿‡flake8 linting
- [ ] **æµ‹è¯•è¦†ç›–**ï¼šå•å…ƒæµ‹è¯•è¦†ç›–ç‡ â‰¥ 80%
- [ ] **é›†æˆæµ‹è¯•**ï¼šæ ¸å¿ƒåŠŸèƒ½é›†æˆæµ‹è¯•é€šè¿‡
- [ ] **æ€§èƒ½æµ‹è¯•**ï¼šå“åº”æ—¶é—´æ»¡è¶³è¦æ±‚
- [ ] **å®‰å…¨æ£€æŸ¥**ï¼šé€šè¿‡banditå®‰å…¨æ‰«æ
- [ ] **æ–‡æ¡£æ›´æ–°**ï¼šAPIæ–‡æ¡£å’ŒREADMEåŒæ­¥æ›´æ–°

### ä»£ç å®¡æŸ¥æ¸…å•
- [ ] **SOLIDåŸåˆ™**ï¼šéµå¾ªè®¾è®¡åŸåˆ™
- [ ] **é”™è¯¯å¤„ç†**ï¼šé€‚å½“çš„å¼‚å¸¸å¤„ç†å’Œé™çº§é€»è¾‘
- [ ] **æ—¥å¿—è®°å½•**ï¼šå…³é”®æ“ä½œæœ‰æ—¥å¿—è®°å½•
- [ ] **ç›‘æ§æŒ‡æ ‡**ï¼šæ·»åŠ å¿…è¦çš„ç›‘æ§æŒ‡æ ‡
- [ ] **é…ç½®ç®¡ç†**ï¼šé¿å…ç¡¬ç¼–ç ï¼Œä½¿ç”¨é…ç½®
- [ ] **èµ„æºç®¡ç†**ï¼šé€‚å½“çš„èµ„æºæ¸…ç†å’Œè¿æ¥ç®¡ç†
- [ ] **å®‰å…¨è€ƒè™‘**ï¼šè¾“å…¥éªŒè¯å’Œæ•°æ®ä¿æŠ¤

---

## ğŸ”„ æŒç»­æ”¹è¿›æµç¨‹

### æ¯å‘¨ä»£ç è´¨é‡å›é¡¾
1. **æŒ‡æ ‡æ”¶é›†**ï¼šæ”¶é›†ä»£ç è´¨é‡ã€æµ‹è¯•è¦†ç›–ç‡ã€æ€§èƒ½æŒ‡æ ‡
2. **é—®é¢˜è¯†åˆ«**ï¼šè¯†åˆ«ä»£ç è´¨é‡é—®é¢˜å’ŒæŠ€æœ¯å€ºåŠ¡
3. **æ”¹è¿›è®¡åˆ’**ï¼šåˆ¶å®šä¸‹å‘¨çš„ä»£ç è´¨é‡æ”¹è¿›è®¡åˆ’
4. **çŸ¥è¯†åˆ†äº«**ï¼šåˆ†äº«æœ€ä½³å®è·µå’Œè¸©å‘ç»éªŒ

### æ¯æœˆæ¶æ„å›é¡¾
1. **æ¶æ„è¯„ä¼°**ï¼šè¯„ä¼°å½“å‰æ¶æ„æ˜¯å¦æ»¡è¶³ä¸šåŠ¡éœ€æ±‚
2. **æ€§èƒ½åˆ†æ**ï¼šåˆ†æç³»ç»Ÿæ€§èƒ½å’Œç“¶é¢ˆ
3. **æŠ€æœ¯æ ˆè¯„ä¼°**ï¼šè¯„ä¼°æŠ€æœ¯é€‰å‹æ˜¯å¦ä»ç„¶åˆé€‚
4. **æ¼”è¿›è§„åˆ’**ï¼šåˆ¶å®šä¸‹é˜¶æ®µçš„æ¶æ„æ¼”è¿›è®¡åˆ’

---

*å¼€å‘è§„èŒƒæ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0*  
*åˆ›å»ºæ—¶é—´ï¼š2025-07-31*  
*ç»´æŠ¤è€…ï¼šå¼€å‘å›¢é˜Ÿ*