# æ•°å­—å‘˜å·¥ç³»ç»Ÿå¼€å‘è§„èŒƒ
## Digital Employee System Development Standards v2.0

### ğŸ“‹ æ–‡æ¡£ä¿¡æ¯
- **æ–‡æ¡£ç‰ˆæœ¬**: v2.0.0
- **æ›´æ–°æ—¥æœŸ**: 2024-07-24
- **é€‚ç”¨èŒƒå›´**: æ•°å­—å‘˜å·¥ç³»ç»Ÿå…¨éƒ¨å¼€å‘å·¥ä½œ
- **ç»´æŠ¤å›¢é˜Ÿ**: æ•°å­—å‘˜å·¥ç³»ç»ŸæŠ€æœ¯å›¢é˜Ÿ

---

## ğŸ¯ è§„èŒƒæ¦‚è¿°

æœ¬æ–‡æ¡£å®šä¹‰äº†æ•°å­—å‘˜å·¥ç³»ç»Ÿçš„å®Œæ•´å¼€å‘è§„èŒƒï¼Œç¡®ä¿ä»£ç è´¨é‡ã€ç³»ç»Ÿç¨³å®šæ€§å’Œå›¢é˜Ÿåä½œæ•ˆç‡ã€‚æ‰€æœ‰å¼€å‘äººå‘˜å¿…é¡»ä¸¥æ ¼éµå®ˆè¿™äº›è§„èŒƒã€‚

---

## ğŸ’» æŠ€æœ¯å¼€å‘è§„èŒƒ

### 1. ä»£ç ç»“æ„è§„èŒƒ

#### 1.1 é¡¹ç›®ç»“æ„æ ‡å‡†
```
digital_employee_system/
â”œâ”€â”€ digital_employee_core/           # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py                 # æ¨¡å—å…¥å£
â”‚   â”œâ”€â”€ intent_recognition.py       # æ„å›¾è¯†åˆ«å¼•æ“
â”‚   â”œâ”€â”€ task_planner.py            # ä»»åŠ¡è§„åˆ’å™¨
â”‚   â”œâ”€â”€ agent_scheduler.py         # Agentè°ƒåº¦å™¨
â”‚   â”œâ”€â”€ enterprise_agents.py       # ä¼ä¸šAgentå®ç°
â”‚   â”œâ”€â”€ digital_employee_system.py # ç³»ç»Ÿæ§åˆ¶å™¨
â”‚   â””â”€â”€ tests/                     # å•å…ƒæµ‹è¯•
â”œâ”€â”€ memory_engine/                  # è®°å¿†å¼•æ“æ¨¡å—
â”œâ”€â”€ integration_tests/              # é›†æˆæµ‹è¯•
â”œâ”€â”€ docs/                          # æ–‡æ¡£
â”œâ”€â”€ config/                        # é…ç½®æ–‡ä»¶
â”œâ”€â”€ scripts/                       # éƒ¨ç½²è„šæœ¬
â””â”€â”€ requirements.txt               # ä¾èµ–æ–‡ä»¶
```

#### 1.2 æ–‡ä»¶å‘½åè§„èŒƒ
- **Pythonæ–‡ä»¶**: ä½¿ç”¨è›‡å½¢å‘½åæ³• `snake_case.py`
- **ç±»å**: ä½¿ç”¨å¸•æ–¯å¡å‘½åæ³• `PascalCase`
- **å‡½æ•°å**: ä½¿ç”¨è›‡å½¢å‘½åæ³• `snake_case`
- **å¸¸é‡**: ä½¿ç”¨å¤§å†™è›‡å½¢å‘½åæ³• `CONSTANT_NAME`
- **ç§æœ‰å±æ€§/æ–¹æ³•**: ä½¿ç”¨å•ä¸‹åˆ’çº¿å‰ç¼€ `_private_method`

### 2. ç¼–ç è§„èŒƒ

#### 2.1 Pythonç¼–ç æ ‡å‡†
```python
"""
æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
æè¿°æ¨¡å—çš„åŠŸèƒ½å’Œç”¨é€”
"""

from typing import Dict, List, Optional, Union, Any
from abc import ABC, abstractmethod
from dataclasses import dataclass
import asyncio
import logging

logger = logging.getLogger(__name__)

@dataclass
class AgentRequest:
    """Agentè¯·æ±‚æ•°æ®ç±»
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥å†…å®¹
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        priority: ä¼˜å…ˆçº§ (1-10)
    """
    user_input: str
    context: Dict[str, Any]
    priority: int = 5
    
    def __post_init__(self):
        """æ•°æ®éªŒè¯"""
        if not self.user_input.strip():
            raise ValueError("ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º")
        if not 1 <= self.priority <= 10:
            raise ValueError("ä¼˜å…ˆçº§å¿…é¡»åœ¨1-10ä¹‹é—´")

class BaseAgent(ABC):
    """AgentåŸºç±»
    
    å®šä¹‰æ‰€æœ‰Agentçš„é€šç”¨æ¥å£å’Œè¡Œä¸º
    """
    
    def __init__(self, agent_id: str, capabilities: List[str]):
        self.agent_id = agent_id
        self.capabilities = capabilities
        self._initialized = False
        logger.info(f"åˆå§‹åŒ–Agent: {agent_id}")
    
    @abstractmethod
    async def execute_task(self, request: AgentRequest) -> Dict[str, Any]:
        """æ‰§è¡Œä»»åŠ¡çš„æŠ½è±¡æ–¹æ³•
        
        Args:
            request: Agentè¯·æ±‚å¯¹è±¡
            
        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœ
            
        Raises:
            AgentExecutionError: ä»»åŠ¡æ‰§è¡Œå¤±è´¥æ—¶æŠ›å‡º
        """
        pass
    
    async def _validate_request(self, request: AgentRequest) -> bool:
        """è¯·æ±‚éªŒè¯
        
        Args:
            request: å¾…éªŒè¯çš„è¯·æ±‚
            
        Returns:
            éªŒè¯æ˜¯å¦é€šè¿‡
        """
        try:
            # éªŒè¯é€»è¾‘
            return True
        except Exception as e:
            logger.error(f"è¯·æ±‚éªŒè¯å¤±è´¥: {str(e)}")
            return False
```

#### 2.2 ä»£ç è´¨é‡è¦æ±‚
- **ç±»å‹æ³¨è§£**: æ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰å®Œæ•´çš„ç±»å‹æ³¨è§£
- **æ–‡æ¡£å­—ç¬¦ä¸²**: æ‰€æœ‰ç±»å’Œå…¬å…±æ–¹æ³•å¿…é¡»æœ‰docstring
- **å¼‚å¸¸å¤„ç†**: å¿…é¡»æœ‰é€‚å½“çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
- **å•å…ƒæµ‹è¯•**: æ ¸å¿ƒåŠŸèƒ½å¿…é¡»æœ‰å•å…ƒæµ‹è¯•è¦†ç›–
- **ä»£ç å¤æ‚åº¦**: å‡½æ•°å¤æ‚åº¦ä¸è¶…è¿‡10ï¼Œç±»å¤æ‚åº¦ä¸è¶…è¿‡20

#### 2.3 å¼‚æ­¥ç¼–ç¨‹è§„èŒƒ
```python
import asyncio
from typing import Coroutine, Any

class AsyncAgentManager:
    """å¼‚æ­¥Agentç®¡ç†å™¨"""
    
    def __init__(self):
        self._agents: Dict[str, BaseAgent] = {}
        self._semaphore = asyncio.Semaphore(10)  # å¹¶å‘æ§åˆ¶
    
    async def execute_parallel_tasks(
        self, 
        tasks: List[Coroutine[Any, Any, Any]]
    ) -> List[Any]:
        """å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
        
        Args:
            tasks: åç¨‹ä»»åŠ¡åˆ—è¡¨
            
        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        async with self._semaphore:
            try:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                return self._process_results(results)
            except Exception as e:
                logger.error(f"å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
                raise
    
    def _process_results(self, results: List[Any]) -> List[Any]:
        """å¤„ç†å¹¶è¡Œæ‰§è¡Œç»“æœ"""
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(result)}")
                processed_results.append({"error": str(result)})
            else:
                processed_results.append(result)
        return processed_results
```

### 3. æµ‹è¯•è§„èŒƒ

#### 3.1 å•å…ƒæµ‹è¯•æ ‡å‡†
```python
import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch

class TestBaseAgent:
    """AgentåŸºç±»æµ‹è¯•"""
    
    @pytest.fixture
    def mock_agent(self):
        """æµ‹è¯•Agent fixture"""
        class TestAgent(BaseAgent):
            async def execute_task(self, request):
                return {"status": "success", "result": "test"}
        
        return TestAgent("test_agent", ["test_capability"])
    
    @pytest.mark.asyncio
    async def test_execute_task_success(self, mock_agent):
        """æµ‹è¯•ä»»åŠ¡æ‰§è¡ŒæˆåŠŸåœºæ™¯"""
        request = AgentRequest(
            user_input="test input",
            context={"test": "context"}
        )
        
        result = await mock_agent.execute_task(request)
        
        assert result["status"] == "success"
        assert result["result"] == "test"
    
    @pytest.mark.asyncio
    async def test_execute_task_with_invalid_input(self, mock_agent):
        """æµ‹è¯•æ— æ•ˆè¾“å…¥åœºæ™¯"""
        with pytest.raises(ValueError, match="ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º"):
            AgentRequest(user_input="", context={})
    
    @patch('logging.Logger.error')
    def test_error_logging(self, mock_logger, mock_agent):
        """æµ‹è¯•é”™è¯¯æ—¥å¿—è®°å½•"""
        # æµ‹è¯•é€»è¾‘
        mock_logger.assert_called_once()
```

#### 3.2 é›†æˆæµ‹è¯•æ ‡å‡†
```python
import pytest
from digital_employee_core import quick_setup_system

class TestSystemIntegration:
    """ç³»ç»Ÿé›†æˆæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_complete_workflow(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹"""
        # è®¾ç½®ç³»ç»Ÿ
        system = await quick_setup_system()
        
        # æµ‹è¯•ç”¨æˆ·è¯·æ±‚å¤„ç†
        response = await system.process_user_request(
            "åˆ†æç”¨æˆ·æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š"
        )
        
        # éªŒè¯å“åº”
        assert response.status in ["success", "partial"]
        assert response.processing_time > 0
        assert len(response.agent_contributions) > 0
        assert 0 <= response.confidence_score <= 1
    
    @pytest.mark.asyncio
    async def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†æœºåˆ¶"""
        system = await quick_setup_system()
        
        # æµ‹è¯•å¼‚å¸¸è¾“å…¥
        response = await system.process_user_request("")
        
        assert response.status == "failed"
        assert "error" in response.result
```

#### 3.3 æ€§èƒ½æµ‹è¯•æ ‡å‡†
```python
import time
import asyncio
import pytest

class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½"""
        system = await quick_setup_system()
        
        # åˆ›å»º50ä¸ªå¹¶å‘è¯·æ±‚
        tasks = []
        for i in range(50):
            task = system.process_user_request(f"æµ‹è¯•è¯·æ±‚ {i}")
            tasks.append(task)
        
        start_time = time.time()
        results = await asyncio.gather(*tasks)
        end_time = time.time()
        
        # æ€§èƒ½æ–­è¨€
        assert end_time - start_time < 30  # 30ç§’å†…å®Œæˆ
        success_count = len([r for r in results if r.status == "success"])
        assert success_count / len(results) >= 0.9  # 90%æˆåŠŸç‡
```

---

## ğŸ”Œ APIæ¥å£è§„èŒƒ

### 1. RESTful APIè®¾è®¡æ ‡å‡†

#### 1.1 URLè®¾è®¡è§„èŒƒ
```
åŸºç¡€URL: https://api.digitalemployee.com/v2/

èµ„æºå‘½åè§„èŒƒ:
GET    /agents                    # è·å–æ‰€æœ‰Agent
GET    /agents/{agent_id}         # è·å–ç‰¹å®šAgent
POST   /agents                    # åˆ›å»ºAgent
PUT    /agents/{agent_id}         # æ›´æ–°Agent
DELETE /agents/{agent_id}         # åˆ é™¤Agent

GET    /tasks                     # è·å–ä»»åŠ¡åˆ—è¡¨
POST   /tasks                     # åˆ›å»ºæ–°ä»»åŠ¡
GET    /tasks/{task_id}           # è·å–ä»»åŠ¡è¯¦æƒ…
PUT    /tasks/{task_id}/status    # æ›´æ–°ä»»åŠ¡çŠ¶æ€

POST   /requests/process          # å¤„ç†ç”¨æˆ·è¯·æ±‚
GET    /requests/{request_id}     # è·å–è¯·æ±‚çŠ¶æ€
GET    /system/health             # ç³»ç»Ÿå¥åº·æ£€æŸ¥
GET    /system/metrics           # ç³»ç»ŸæŒ‡æ ‡
```

#### 1.2 HTTPçŠ¶æ€ç è§„èŒƒ
```
æˆåŠŸå“åº”:
200 OK              - è¯·æ±‚æˆåŠŸ
201 Created         - èµ„æºåˆ›å»ºæˆåŠŸ
202 Accepted        - è¯·æ±‚å·²æ¥å—ï¼Œå¼‚æ­¥å¤„ç†ä¸­
204 No Content      - è¯·æ±‚æˆåŠŸä½†æ— è¿”å›å†…å®¹

å®¢æˆ·ç«¯é”™è¯¯:
400 Bad Request     - è¯·æ±‚å‚æ•°é”™è¯¯
401 Unauthorized    - æœªè®¤è¯
403 Forbidden       - æ— æƒé™
404 Not Found       - èµ„æºä¸å­˜åœ¨
409 Conflict        - èµ„æºå†²çª
422 Unprocessable   - è¯·æ±‚æ ¼å¼æ­£ç¡®ä½†è¯­ä¹‰é”™è¯¯
429 Too Many Requests - è¯·æ±‚é¢‘ç‡è¶…é™

æœåŠ¡å™¨é”™è¯¯:
500 Internal Server Error - æœåŠ¡å™¨å†…éƒ¨é”™è¯¯
502 Bad Gateway          - ç½‘å…³é”™è¯¯
503 Service Unavailable  - æœåŠ¡ä¸å¯ç”¨
504 Gateway Timeout      - ç½‘å…³è¶…æ—¶
```

#### 1.3 è¯·æ±‚/å“åº”æ ¼å¼æ ‡å‡†

**æ ‡å‡†è¯·æ±‚æ ¼å¼:**
```json
{
  "data": {
    "user_input": "åˆ†æé”€å”®æ•°æ®",
    "context": {
      "department": "sales",
      "priority": "high"
    },
    "options": {
      "timeout": 30,
      "require_explanation": true
    }
  },
  "metadata": {
    "request_id": "req_123456",
    "user_id": "user_001",
    "timestamp": "2024-07-24T10:30:00Z"
  }
}
```

**æ ‡å‡†å“åº”æ ¼å¼:**
```json
{
  "success": true,
  "data": {
    "status": "success",
    "result": "åˆ†æç»“æœå†…å®¹",
    "agent_contributions": [
      {
        "agent_id": "finance_analyst_001",
        "role": "è´¢åŠ¡åˆ†æå¸ˆ",
        "contribution": "è´¢åŠ¡æ•°æ®åˆ†æ",
        "confidence": 0.95
      }
    ],
    "processing_time": 2.5,
    "confidence_score": 0.92
  },
  "metadata": {
    "request_id": "req_123456",
    "response_id": "resp_789012",
    "timestamp": "2024-07-24T10:30:02Z",
    "api_version": "v2.0"
  },
  "pagination": {
    "page": 1,
    "limit": 20,
    "total": 100,
    "has_more": true
  }
}
```

**é”™è¯¯å“åº”æ ¼å¼:**
```json
{
  "success": false,
  "error": {
    "code": "INVALID_INPUT",
    "message": "ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º",
    "details": {
      "field": "user_input",
      "reason": "required_field_missing"
    },
    "suggestion": "è¯·æä¾›æœ‰æ•ˆçš„ç”¨æˆ·è¾“å…¥å†…å®¹"
  },
  "metadata": {
    "request_id": "req_123456",
    "timestamp": "2024-07-24T10:30:00Z",
    "api_version": "v2.0"
  }
}
```

### 2. APIæ¥å£å®ç°æ ‡å‡†

#### 2.1 FastAPIå®ç°ç¤ºä¾‹
```python
from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field, validator
from typing import Optional, List, Dict, Any
from datetime import datetime
import uuid

app = FastAPI(
    title="æ•°å­—å‘˜å·¥ç³»ç»ŸAPI",
    description="ä¼ä¸šçº§Multi-Agentç³»ç»ŸAPIæ¥å£",
    version="2.0.0"
)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ProcessRequest(BaseModel):
    """å¤„ç†è¯·æ±‚æ¨¡å‹"""
    user_input: str = Field(..., min_length=1, description="ç”¨æˆ·è¾“å…¥")
    context: Optional[Dict[str, Any]] = Field(default={}, description="ä¸Šä¸‹æ–‡")
    options: Optional[Dict[str, Any]] = Field(default={}, description="é€‰é¡¹")
    
    @validator('user_input')
    def validate_user_input(cls, v):
        if not v.strip():
            raise ValueError('ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º')
        return v.strip()

class ProcessResponse(BaseModel):
    """å¤„ç†å“åº”æ¨¡å‹"""
    success: bool
    data: Optional[Dict[str, Any]] = None
    error: Optional[Dict[str, Any]] = None
    metadata: Dict[str, Any]

@app.post("/v2/requests/process", response_model=ProcessResponse)
async def process_request(
    request: ProcessRequest,
    user_id: Optional[str] = None
):
    """å¤„ç†ç”¨æˆ·è¯·æ±‚"""
    request_id = str(uuid.uuid4())
    
    try:
        # è·å–æ•°å­—å‘˜å·¥ç³»ç»Ÿå®ä¾‹
        system = await get_digital_employee_system()
        
        # å¤„ç†è¯·æ±‚
        response = await system.process_user_request(
            user_input=request.user_input,
            context=request.context,
            user_id=user_id
        )
        
        return ProcessResponse(
            success=True,
            data={
                "status": response.status,
                "result": response.result,
                "agent_contributions": response.agent_contributions,
                "processing_time": response.processing_time,
                "confidence_score": response.confidence_score
            },
            metadata={
                "request_id": request_id,
                "timestamp": datetime.utcnow().isoformat(),
                "api_version": "v2.0"
            }
        )
        
    except Exception as e:
        logger.error(f"è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}")
        return ProcessResponse(
            success=False,
            error={
                "code": "PROCESSING_ERROR",
                "message": str(e),
                "suggestion": "è¯·æ£€æŸ¥è¾“å…¥å‚æ•°æˆ–ç¨åé‡è¯•"
            },
            metadata={
                "request_id": request_id,
                "timestamp": datetime.utcnow().isoformat(),
                "api_version": "v2.0"
            }
        )

@app.get("/v2/system/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        system = await get_digital_employee_system()
        status = system.get_system_status()
        
        return {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "system_info": {
                "registered_agents": status["registered_agents"],
                "success_rate": status["success_rate"],
                "uptime": status["uptime_seconds"]
            }
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=f"ç³»ç»Ÿä¸å¥åº·: {str(e)}"
        )
```

#### 2.2 è®¤è¯å’Œæˆæƒ
```python
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt

security = HTTPBearer()

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """éªŒè¯JWTä»¤ç‰Œ"""
    try:
        payload = jwt.decode(
            credentials.credentials, 
            SECRET_KEY, 
            algorithms=["HS256"]
        )
        user_id = payload.get("user_id")
        if user_id is None:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="æ— æ•ˆçš„è®¤è¯ä»¤ç‰Œ"
            )
        return user_id
    except jwt.PyJWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ä»¤ç‰ŒéªŒè¯å¤±è´¥"
        )

@app.post("/v2/requests/process")
async def process_request(
    request: ProcessRequest,
    user_id: str = Depends(verify_token)
):
    """éœ€è¦è®¤è¯çš„æ¥å£"""
    # æ¥å£å®ç°
    pass
```

#### 2.3 APIæ–‡æ¡£å’Œæµ‹è¯•
```python
# APIæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ
@app.get("/v2/agents", tags=["agents"], summary="è·å–Agentåˆ—è¡¨")
async def get_agents(
    limit: int = Query(20, ge=1, le=100, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡"),
    department: Optional[str] = Query(None, description="éƒ¨é—¨ç­›é€‰")
):
    """
    è·å–ç³»ç»Ÿä¸­æ‰€æœ‰Agentçš„åˆ—è¡¨
    
    - **limit**: è¿”å›ç»“æœæ•°é‡é™åˆ¶ (1-100)
    - **offset**: åˆ†é¡µåç§»é‡
    - **department**: æŒ‰éƒ¨é—¨ç­›é€‰Agent
    
    è¿”å›Agentåˆ—è¡¨ï¼ŒåŒ…å«æ¯ä¸ªAgentçš„åŸºæœ¬ä¿¡æ¯å’Œèƒ½åŠ›æè¿°
    """
    pass

# APIæµ‹è¯•ç”¨ä¾‹
class TestAPI:
    """APIæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_process_request_success(self, client):
        """æµ‹è¯•è¯·æ±‚å¤„ç†æˆåŠŸåœºæ™¯"""
        response = await client.post("/v2/requests/process", json={
            "user_input": "åˆ†æé”€å”®æ•°æ®",
            "context": {"department": "sales"}
        })
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "processing_time" in data["data"]
    
    @pytest.mark.asyncio
    async def test_health_check(self, client):
        """æµ‹è¯•å¥åº·æ£€æŸ¥"""
        response = await client.get("/v2/system/health")
        
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"
```

---

## ğŸ—„ï¸ æ•°æ®åº“è®¾è®¡è§„èŒƒ

### 1. æ•°æ®åº“æ¶æ„æ ‡å‡†

#### 1.1 æ•°æ®åº“é€‰å‹è§„èŒƒ
```yaml
ä¸»æ•°æ®åº“:
  ç±»å‹: PostgreSQL 14+
  ç”¨é€”: ä¸šåŠ¡æ•°æ®å­˜å‚¨
  ç‰¹æ€§: ACIDäº‹åŠ¡, JSONæ”¯æŒ, å…¨æ–‡æœç´¢

ç¼“å­˜æ•°æ®åº“:
  ç±»å‹: Redis 6+
  ç”¨é€”: ç¼“å­˜, ä¼šè¯å­˜å‚¨, æ¶ˆæ¯é˜Ÿåˆ—
  ç‰¹æ€§: é«˜æ€§èƒ½, æ•°æ®ç»“æ„ä¸°å¯Œ

æ—¶åºæ•°æ®åº“:
  ç±»å‹: InfluxDB 2.0+
  ç”¨é€”: ç›‘æ§æŒ‡æ ‡, æ€§èƒ½æ•°æ®
  ç‰¹æ€§: æ—¶é—´åºåˆ—ä¼˜åŒ–, é«˜å†™å…¥æ€§èƒ½

æœç´¢å¼•æ“:
  ç±»å‹: Elasticsearch 8+
  ç”¨é€”: å…¨æ–‡æœç´¢, æ—¥å¿—åˆ†æ
  ç‰¹æ€§: åˆ†å¸ƒå¼æœç´¢, å®æ—¶åˆ†æ
```

#### 1.2 æ•°æ®åº“è¿æ¥é…ç½®
```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import QueuePool
import os

# æ•°æ®åº“é…ç½®
DATABASE_CONFIG = {
    "host": os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("DB_PORT", 5432),
    "database": os.getenv("DB_NAME", "digital_employee"),
    "username": os.getenv("DB_USER", "postgres"),
    "password": os.getenv("DB_PASSWORD", "password"),
    "pool_size": 20,
    "max_overflow": 30,
    "pool_timeout": 30,
    "pool_recycle": 3600
}

# æ•°æ®åº“å¼•æ“
DATABASE_URL = f"postgresql://{DATABASE_CONFIG['username']}:{DATABASE_CONFIG['password']}@{DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}"

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=DATABASE_CONFIG["pool_size"],
    max_overflow=DATABASE_CONFIG["max_overflow"],
    pool_timeout=DATABASE_CONFIG["pool_timeout"],
    pool_recycle=DATABASE_CONFIG["pool_recycle"],
    echo=False  # ç”Ÿäº§ç¯å¢ƒè®¾ç½®ä¸ºFalse
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    @staticmethod
    def get_db():
        """è·å–æ•°æ®åº“ä¼šè¯"""
        db = SessionLocal()
        try:
            yield db
        finally:
            db.close()
    
    @staticmethod
    async def execute_with_retry(query, max_retries=3):
        """å¸¦é‡è¯•çš„æŸ¥è¯¢æ‰§è¡Œ"""
        for attempt in range(max_retries):
            try:
                db = SessionLocal()
                result = db.execute(query)
                db.commit()
                return result
            except Exception as e:
                db.rollback()
                if attempt == max_retries - 1:
                    raise e
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            finally:
                db.close()
```

### 2. æ•°æ®æ¨¡å‹è®¾è®¡æ ‡å‡†

#### 2.1 åŸºç¡€æ¨¡å‹ç±»
```python
from sqlalchemy import Column, Integer, String, DateTime, Boolean, Text, JSON
from sqlalchemy.sql import func
from datetime import datetime
import uuid

class BaseModel(Base):
    """åŸºç¡€æ¨¡å‹ç±»"""
    __abstract__ = True
    
    id = Column(Integer, primary_key=True, index=True)
    uuid = Column(String(36), unique=True, index=True, default=lambda: str(uuid.uuid4()))
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    created_by = Column(String(100), nullable=True)
    updated_by = Column(String(100), nullable=True)
    is_deleted = Column(Boolean, default=False)
    version = Column(Integer, default=1)
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            column.name: getattr(self, column.name)
            for column in self.__table__.columns
        }
    
    def soft_delete(self):
        """è½¯åˆ é™¤"""
        self.is_deleted = True
        self.updated_at = datetime.utcnow()
```

#### 2.2 ç´¢å¼•è®¾è®¡è§„èŒƒ
```python
from sqlalchemy import Index

class AgentModel(BaseModel):
    """Agentæ¨¡å‹"""
    __tablename__ = "agents"
    
    agent_id = Column(String(100), unique=True, nullable=False, index=True)
    role = Column(String(50), nullable=False, index=True)
    department = Column(String(50), nullable=False, index=True)
    status = Column(String(20), default="active", index=True)
    capabilities = Column(JSON, nullable=False)
    config = Column(JSON, nullable=True)
    
    # å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_agent_role_dept', 'role', 'department'),
        Index('idx_agent_status_created', 'status', 'created_at'),
        Index('idx_agent_dept_status', 'department', 'status', 'is_deleted'),
    )

class TaskModel(BaseModel):
    """ä»»åŠ¡æ¨¡å‹"""
    __tablename__ = "tasks"
    
    task_id = Column(String(100), unique=True, nullable=False, index=True)
    user_input = Column(Text, nullable=False)
    context = Column(JSON, nullable=True)
    priority = Column(Integer, default=5, index=True)
    status = Column(String(20), default="pending", index=True)
    assigned_agent_id = Column(String(100), nullable=True, index=True)
    result = Column(JSON, nullable=True)
    processing_time = Column(Integer, nullable=True)  # æ¯«ç§’
    
    # åˆ†åŒºè¡¨ç´¢å¼• (æŒ‰åˆ›å»ºæ—¶é—´)
    __table_args__ = (
        Index('idx_task_status_priority', 'status', 'priority'),
        Index('idx_task_agent_status', 'assigned_agent_id', 'status'),
        Index('idx_task_created_status', 'created_at', 'status'),
    )
```

---

## ğŸ“Š æ•°æ®åº“è¡¨è®¾è®¡è§„èŒƒ

### 1. è¡¨è®¾è®¡æ ‡å‡†

#### 1.1 å‘½åè§„èŒƒ
```sql
-- è¡¨å‘½åè§„èŒƒ
è¡¨å: å¤æ•°å½¢å¼ï¼Œä¸‹åˆ’çº¿åˆ†éš”
  âœ“ agents, tasks, user_requests
  âœ— agent, Task, UserRequest

-- å­—æ®µå‘½åè§„èŒƒ
å­—æ®µå: ä¸‹åˆ’çº¿åˆ†éš”ï¼Œæè¿°æ€§å¼º
  âœ“ created_at, agent_id, processing_time
  âœ— createdAt, aid, time

-- ç´¢å¼•å‘½åè§„èŒƒ
ç´¢å¼•å: idx_è¡¨å_å­—æ®µå
  âœ“ idx_agents_role, idx_tasks_status_priority
  âœ— agent_role_index, task_idx

-- çº¦æŸå‘½åè§„èŒƒ
ä¸»é”®: pk_è¡¨å
å¤–é”®: fk_è¡¨å_å¼•ç”¨è¡¨å_å­—æ®µå
å”¯ä¸€: uk_è¡¨å_å­—æ®µå
æ£€æŸ¥: ck_è¡¨å_å­—æ®µå
```

#### 1.2 æ ¸å¿ƒä¸šåŠ¡è¡¨è®¾è®¡

**1. Agentç®¡ç†è¡¨**
```sql
-- Agentæ³¨å†Œè¡¨
CREATE TABLE agents (
    id SERIAL PRIMARY KEY,
    uuid VARCHAR(36) UNIQUE NOT NULL DEFAULT gen_random_uuid(),
    agent_id VARCHAR(100) UNIQUE NOT NULL,
    role VARCHAR(50) NOT NULL,
    department VARCHAR(50) NOT NULL,
    status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'maintenance')),
    capabilities JSONB NOT NULL DEFAULT '[]',
    config JSONB DEFAULT '{}',
    performance_metrics JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    updated_by VARCHAR(100),
    is_deleted BOOLEAN DEFAULT FALSE,
    version INTEGER DEFAULT 1
);

-- ç´¢å¼•
CREATE INDEX idx_agents_role ON agents(role) WHERE is_deleted = FALSE;
CREATE INDEX idx_agents_department ON agents(department) WHERE is_deleted = FALSE;
CREATE INDEX idx_agents_status ON agents(status) WHERE is_deleted = FALSE;
CREATE INDEX idx_agents_role_dept ON agents(role, department) WHERE is_deleted = FALSE;
CREATE INDEX idx_agents_capabilities ON agents USING GIN (capabilities);

-- æ³¨é‡Š
COMMENT ON TABLE agents IS 'Agentæ³¨å†Œå’Œç®¡ç†è¡¨';
COMMENT ON COLUMN agents.agent_id IS 'Agentå”¯ä¸€æ ‡è¯†ç¬¦';
COMMENT ON COLUMN agents.role IS 'Agentè§’è‰²ç±»å‹';
COMMENT ON COLUMN agents.capabilities IS 'Agentèƒ½åŠ›åˆ—è¡¨ï¼ŒJSONæ ¼å¼';
COMMENT ON COLUMN agents.performance_metrics IS 'æ€§èƒ½æŒ‡æ ‡ï¼ŒJSONæ ¼å¼';
```

**2. ä»»åŠ¡ç®¡ç†è¡¨**
```sql
-- ä»»åŠ¡ä¸»è¡¨
CREATE TABLE tasks (
    id SERIAL PRIMARY KEY,
    uuid VARCHAR(36) UNIQUE NOT NULL DEFAULT gen_random_uuid(),
    task_id VARCHAR(100) UNIQUE NOT NULL,
    user_input TEXT NOT NULL,
    context JSONB DEFAULT '{}',
    priority INTEGER DEFAULT 5 CHECK (priority BETWEEN 1 AND 10),
    complexity_level INTEGER CHECK (complexity_level BETWEEN 1 AND 10),
    urgency_level VARCHAR(20) CHECK (urgency_level IN ('LOW', 'MEDIUM', 'HIGH', 'CRITICAL')),
    status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'assigned', 'processing', 'completed', 'failed', 'cancelled')),
    assigned_agent_id VARCHAR(100),
    result JSONB,
    error_info JSONB,
    processing_time INTEGER, -- æ¯«ç§’
    start_time TIMESTAMP WITH TIME ZONE,
    end_time TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    updated_by VARCHAR(100),
    is_deleted BOOLEAN DEFAULT FALSE,
    version INTEGER DEFAULT 1
);

-- åˆ†åŒºè¡¨ (æŒ‰æœˆåˆ†åŒº)
CREATE TABLE tasks_y2024m07 PARTITION OF tasks
    FOR VALUES FROM ('2024-07-01') TO ('2024-08-01');
CREATE TABLE tasks_y2024m08 PARTITION OF tasks
    FOR VALUES FROM ('2024-08-01') TO ('2024-09-01');

-- ç´¢å¼•
CREATE INDEX idx_tasks_status ON tasks(status) WHERE is_deleted = FALSE;
CREATE INDEX idx_tasks_priority ON tasks(priority) WHERE is_deleted = FALSE;
CREATE INDEX idx_tasks_agent_id ON tasks(assigned_agent_id) WHERE is_deleted = FALSE;
CREATE INDEX idx_tasks_status_priority ON tasks(status, priority) WHERE is_deleted = FALSE;
CREATE INDEX idx_tasks_created_at ON tasks(created_at) WHERE is_deleted = FALSE;
CREATE INDEX idx_tasks_context ON tasks USING GIN (context);

-- å¤–é”®çº¦æŸ
ALTER TABLE tasks ADD CONSTRAINT fk_tasks_agents 
    FOREIGN KEY (assigned_agent_id) REFERENCES agents(agent_id);
```

**3. ç”¨æˆ·è¯·æ±‚è¡¨**
```sql
-- ç”¨æˆ·è¯·æ±‚è¡¨
CREATE TABLE user_requests (
    id SERIAL PRIMARY KEY,
    uuid VARCHAR(36) UNIQUE NOT NULL DEFAULT gen_random_uuid(),
    request_id VARCHAR(100) UNIQUE NOT NULL,
    user_id VARCHAR(100),
    session_id VARCHAR(100),
    original_input TEXT NOT NULL,
    processed_input TEXT,
    intent_analysis JSONB,
    processing_strategy VARCHAR(50),
    task_ids JSONB DEFAULT '[]', -- å…³è”çš„ä»»åŠ¡IDåˆ—è¡¨
    final_result JSONB,
    confidence_score DECIMAL(3,2) CHECK (confidence_score BETWEEN 0 AND 1),
    processing_time INTEGER, -- æ¯«ç§’
    status VARCHAR(20) DEFAULT 'received' CHECK (status IN ('received', 'processing', 'completed', 'failed')),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    is_deleted BOOLEAN DEFAULT FALSE,
    version INTEGER DEFAULT 1
);

-- ç´¢å¼•
CREATE INDEX idx_user_requests_user_id ON user_requests(user_id) WHERE is_deleted = FALSE;
CREATE INDEX idx_user_requests_session_id ON user_requests(session_id) WHERE is_deleted = FALSE;
CREATE INDEX idx_user_requests_status ON user_requests(status) WHERE is_deleted = FALSE;
CREATE INDEX idx_user_requests_created_at ON user_requests(created_at) WHERE is_deleted = FALSE;
CREATE INDEX idx_user_requests_intent ON user_requests USING GIN (intent_analysis);
```

**4. Agentåä½œè¡¨**
```sql
-- Agentåä½œè®°å½•è¡¨
CREATE TABLE agent_collaborations (
    id SERIAL PRIMARY KEY,
    uuid VARCHAR(36) UNIQUE NOT NULL DEFAULT gen_random_uuid(),
    collaboration_id VARCHAR(100) UNIQUE NOT NULL,
    task_id VARCHAR(100) NOT NULL,
    primary_agent_id VARCHAR(100) NOT NULL,
    participating_agents JSONB NOT NULL DEFAULT '[]',
    collaboration_type VARCHAR(50) NOT NULL,
    workflow_design JSONB,
    coordination_rules JSONB,
    start_time TIMESTAMP WITH TIME ZONE,
    end_time TIMESTAMP WITH TIME ZONE,
    status VARCHAR(20) DEFAULT 'initiated' CHECK (status IN ('initiated', 'coordinating', 'executing', 'integrating', 'completed', 'failed')),
    results JSONB,
    performance_metrics JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    is_deleted BOOLEAN DEFAULT FALSE,
    version INTEGER DEFAULT 1
);

-- å¤–é”®çº¦æŸ
ALTER TABLE agent_collaborations ADD CONSTRAINT fk_collaborations_tasks
    FOREIGN KEY (task_id) REFERENCES tasks(task_id);
ALTER TABLE agent_collaborations ADD CONSTRAINT fk_collaborations_primary_agent
    FOREIGN KEY (primary_agent_id) REFERENCES agents(agent_id);

-- ç´¢å¼•
CREATE INDEX idx_collaborations_task_id ON agent_collaborations(task_id);
CREATE INDEX idx_collaborations_primary_agent ON agent_collaborations(primary_agent_id);
CREATE INDEX idx_collaborations_status ON agent_collaborations(status) WHERE is_deleted = FALSE;
```

### 2. æ•°æ®åˆ†åŒºå’Œå½’æ¡£ç­–ç•¥

#### 2.1 æ—¶é—´åˆ†åŒºç­–ç•¥
```sql
-- æŒ‰æœˆåˆ†åŒºçš„ä»»åŠ¡è¡¨
CREATE TABLE tasks (
    -- å­—æ®µå®šä¹‰
) PARTITION BY RANGE (created_at);

-- åˆ›å»ºåˆ†åŒºå‡½æ•°
CREATE OR REPLACE FUNCTION create_monthly_partitions()
RETURNS void AS $$
DECLARE
    start_date date;
    end_date date;
    partition_name text;
BEGIN
    start_date := date_trunc('month', CURRENT_DATE);
    
    FOR i IN 0..11 LOOP
        end_date := start_date + interval '1 month';
        partition_name := 'tasks_' || to_char(start_date, 'YYYY_MM');
        
        EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF tasks 
                       FOR VALUES FROM (%L) TO (%L)',
                       partition_name, start_date, end_date);
        
        start_date := end_date;
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- å®šæœŸæ‰§è¡Œåˆ†åŒºåˆ›å»º
SELECT create_monthly_partitions();
```

#### 2.2 æ•°æ®å½’æ¡£ç­–ç•¥
```sql
-- åˆ›å»ºå½’æ¡£è¡¨
CREATE TABLE tasks_archive (LIKE tasks INCLUDING ALL);

-- å½’æ¡£å‡½æ•°
CREATE OR REPLACE FUNCTION archive_old_tasks()
RETURNS void AS $$
BEGIN
    -- å½’æ¡£6ä¸ªæœˆå‰çš„å·²å®Œæˆä»»åŠ¡
    INSERT INTO tasks_archive 
    SELECT * FROM tasks 
    WHERE status IN ('completed', 'failed', 'cancelled')
      AND created_at < CURRENT_DATE - INTERVAL '6 months';
    
    -- åˆ é™¤å·²å½’æ¡£çš„æ•°æ®
    DELETE FROM tasks 
    WHERE status IN ('completed', 'failed', 'cancelled')
      AND created_at < CURRENT_DATE - INTERVAL '6 months';
      
    -- æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    ANALYZE tasks;
    ANALYZE tasks_archive;
END;
$$ LANGUAGE plpgsql;

-- å®šæœŸæ‰§è¡Œå½’æ¡£ (é€šè¿‡cron job)
-- 0 2 1 * * /usr/bin/psql -c "SELECT archive_old_tasks();"
```

---

## ğŸ“ å­—æ®µè®¾è®¡è§„èŒƒ

### 1. å­—æ®µç±»å‹æ ‡å‡†

#### 1.1 åŸºç¡€å­—æ®µç±»å‹æ˜ å°„
```sql
-- å­—ç¬¦ä¸²ç±»å‹
çŸ­æ–‡æœ¬ (< 255å­—ç¬¦):     VARCHAR(255)
ä¸­ç­‰æ–‡æœ¬ (< 65535å­—ç¬¦): TEXT
é•¿æ–‡æœ¬ (> 65535å­—ç¬¦):   LONGTEXT
å›ºå®šé•¿åº¦å­—ç¬¦ä¸²:         CHAR(n)

-- æ•°å€¼ç±»å‹
æ•´æ•°:                  INTEGER, BIGINT
å°æ•´æ•°:                SMALLINT
é‡‘é¢:                  DECIMAL(15,2)
ç™¾åˆ†æ¯”:                DECIMAL(5,2)  -- 0.00-999.99
æµ®ç‚¹æ•°:                REAL, DOUBLE PRECISION

-- æ—¶é—´ç±»å‹
æ—¥æœŸæ—¶é—´:              TIMESTAMP WITH TIME ZONE
æ—¥æœŸ:                  DATE
æ—¶é—´:                  TIME
æŒç»­æ—¶é—´:              INTERVAL

-- å¸ƒå°”ç±»å‹
æ˜¯å¦æ ‡å¿—:              BOOLEAN

-- JSONç±»å‹
ç»“æ„åŒ–æ•°æ®:            JSONB (PostgreSQLæ¨è)
é…ç½®ä¿¡æ¯:              JSONB
æ•°ç»„æ•°æ®:              JSONB

-- äºŒè¿›åˆ¶ç±»å‹
æ–‡ä»¶å†…å®¹:              BYTEA
å¤§æ–‡ä»¶:                å­˜å‚¨æ–‡ä»¶è·¯å¾„ï¼Œæ–‡ä»¶å­˜å‚¨åœ¨å¯¹è±¡å­˜å‚¨
```

#### 1.2 å¸¸ç”¨å­—æ®µè®¾è®¡æ¨¡æ¿

**èº«ä»½æ ‡è¯†å­—æ®µ:**
```sql
-- ä¸»é”®ID
id SERIAL PRIMARY KEY

-- UUID (å…¨å±€å”¯ä¸€)
uuid VARCHAR(36) UNIQUE NOT NULL DEFAULT gen_random_uuid()

-- ä¸šåŠ¡ID (äººç±»å¯è¯»)
agent_id VARCHAR(100) UNIQUE NOT NULL
task_id VARCHAR(100) UNIQUE NOT NULL
request_id VARCHAR(100) UNIQUE NOT NULL

-- ç”¨æˆ·æ ‡è¯†
user_id VARCHAR(100) NOT NULL
session_id VARCHAR(100)
```

**æ—¶é—´å­—æ®µ:**
```sql
-- å®¡è®¡æ—¶é—´å­—æ®µ (æ‰€æœ‰è¡¨å¿…å¤‡)
created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP

-- ä¸šåŠ¡æ—¶é—´å­—æ®µ
start_time TIMESTAMP WITH TIME ZONE
end_time TIMESTAMP WITH TIME ZONE
scheduled_time TIMESTAMP WITH TIME ZONE
expire_time TIMESTAMP WITH TIME ZONE

-- æ—¶é—´é—´éš”å­—æ®µ
processing_time INTEGER  -- æ¯«ç§’
timeout_duration INTEGER -- ç§’
retry_interval INTEGER   -- ç§’
```

**çŠ¶æ€å­—æ®µ:**
```sql
-- é€šç”¨çŠ¶æ€å­—æ®µ
status VARCHAR(20) DEFAULT 'active' 
  CHECK (status IN ('active', 'inactive', 'pending', 'processing', 'completed', 'failed'))

-- å¸ƒå°”çŠ¶æ€å­—æ®µ
is_active BOOLEAN DEFAULT TRUE
is_deleted BOOLEAN DEFAULT FALSE
is_public BOOLEAN DEFAULT FALSE
is_verified BOOLEAN DEFAULT FALSE

-- ä¼˜å…ˆçº§å­—æ®µ
priority INTEGER DEFAULT 5 CHECK (priority BETWEEN 1 AND 10)
urgency_level VARCHAR(20) CHECK (urgency_level IN ('LOW', 'MEDIUM', 'HIGH', 'CRITICAL'))
```

**é…ç½®å’Œæ•°æ®å­—æ®µ:**
```sql
-- JSONé…ç½®å­—æ®µ
config JSONB DEFAULT '{}'
metadata JSONB DEFAULT '{}'
options JSONB DEFAULT '{}'
context JSONB DEFAULT '{}'

-- æ•°ç»„å­—æ®µ (ä½¿ç”¨JSONBå­˜å‚¨)
capabilities JSONB DEFAULT '[]'
tags JSONB DEFAULT '[]'
attachments JSONB DEFAULT '[]'

-- è®¡æ•°å­—æ®µ
retry_count INTEGER DEFAULT 0
view_count INTEGER DEFAULT 0
success_count INTEGER DEFAULT 0
failure_count INTEGER DEFAULT 0
```

**æ€§èƒ½å’Œç›‘æ§å­—æ®µ:**
```sql
-- æ€§èƒ½æŒ‡æ ‡
response_time INTEGER    -- æ¯«ç§’
throughput INTEGER       -- æ¯ç§’å¤„ç†æ•°
cpu_usage DECIMAL(5,2)   -- CPUä½¿ç”¨ç‡ç™¾åˆ†æ¯”
memory_usage BIGINT      -- å†…å­˜ä½¿ç”¨å­—èŠ‚æ•°

-- è´¨é‡æŒ‡æ ‡
confidence_score DECIMAL(3,2) CHECK (confidence_score BETWEEN 0 AND 1)
accuracy_rate DECIMAL(5,2)    -- å‡†ç¡®ç‡ç™¾åˆ†æ¯”
error_rate DECIMAL(5,2)       -- é”™è¯¯ç‡ç™¾åˆ†æ¯”

-- ç»Ÿè®¡å­—æ®µ
total_requests INTEGER DEFAULT 0
successful_requests INTEGER DEFAULT 0
failed_requests INTEGER DEFAULT 0
average_processing_time INTEGER DEFAULT 0
```

### 2. å­—æ®µçº¦æŸå’ŒéªŒè¯

#### 2.1 çº¦æŸè§„èŒƒ
```sql
-- éç©ºçº¦æŸ (å…³é”®ä¸šåŠ¡å­—æ®µ)
agent_id VARCHAR(100) NOT NULL
user_input TEXT NOT NULL
status VARCHAR(20) NOT NULL

-- å”¯ä¸€çº¦æŸ
email VARCHAR(255) UNIQUE NOT NULL
phone VARCHAR(20) UNIQUE
agent_id VARCHAR(100) UNIQUE NOT NULL

-- æ£€æŸ¥çº¦æŸ
priority INTEGER CHECK (priority BETWEEN 1 AND 10)
confidence_score DECIMAL(3,2) CHECK (confidence_score BETWEEN 0 AND 1)
status VARCHAR(20) CHECK (status IN ('active', 'inactive', 'pending'))

-- å¤–é”®çº¦æŸ
assigned_agent_id VARCHAR(100) REFERENCES agents(agent_id)
user_id VARCHAR(100) REFERENCES users(user_id)

-- å¤åˆå”¯ä¸€çº¦æŸ
CONSTRAINT uk_agent_role_dept UNIQUE (agent_id, department)
```

#### 2.2 é»˜è®¤å€¼è§„èŒƒ
```sql
-- æ—¶é—´é»˜è®¤å€¼
created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP

-- çŠ¶æ€é»˜è®¤å€¼
status VARCHAR(20) DEFAULT 'active'
is_deleted BOOLEAN DEFAULT FALSE
is_active BOOLEAN DEFAULT TRUE

-- æ•°å€¼é»˜è®¤å€¼
priority INTEGER DEFAULT 5
retry_count INTEGER DEFAULT 0
version INTEGER DEFAULT 1

-- JSONé»˜è®¤å€¼
config JSONB DEFAULT '{}'
capabilities JSONB DEFAULT '[]'
metadata JSONB DEFAULT '{}'

-- UUIDé»˜è®¤å€¼
uuid VARCHAR(36) DEFAULT gen_random_uuid()
```

### 3. å­—æ®µå‘½åå’Œæ³¨é‡Šè§„èŒƒ

#### 3.1 å‘½åè§„èŒƒç¤ºä¾‹
```sql
-- å¥½çš„å­—æ®µå‘½å âœ“
user_id              -- ç”¨æˆ·ID
created_at           -- åˆ›å»ºæ—¶é—´
is_active           -- æ˜¯å¦æ¿€æ´»
processing_time     -- å¤„ç†æ—¶é—´
confidence_score    -- ç½®ä¿¡åº¦åˆ†æ•°
agent_capabilities  -- Agentèƒ½åŠ›

-- ä¸å¥½çš„å­—æ®µå‘½å âœ—
uid                 -- ä¸æ˜ç¡®
time                -- å“ªä¸ªæ—¶é—´ï¼Ÿ
flag                -- ä»€ä¹ˆæ ‡å¿—ï¼Ÿ
data                -- ä»€ä¹ˆæ•°æ®ï¼Ÿ
temp                -- ä¸´æ—¶ä»€ä¹ˆï¼Ÿ
```

#### 3.2 æ³¨é‡Šè§„èŒƒ
```sql
-- è¡¨æ³¨é‡Š
COMMENT ON TABLE agents IS 'Agentæ³¨å†Œå’Œç®¡ç†è¡¨ï¼Œå­˜å‚¨æ‰€æœ‰æ•°å­—å‘˜å·¥Agentçš„åŸºæœ¬ä¿¡æ¯';

-- å­—æ®µæ³¨é‡Š
COMMENT ON COLUMN agents.agent_id IS 'Agentå”¯ä¸€æ ‡è¯†ç¬¦ï¼Œæ ¼å¼ï¼šè§’è‰²_éƒ¨é—¨_åºå·';
COMMENT ON COLUMN agents.capabilities IS 'Agentèƒ½åŠ›åˆ—è¡¨ï¼ŒJSONæ•°ç»„æ ¼å¼ï¼ŒåŒ…å«æŠ€èƒ½å’Œä¸“é•¿';
COMMENT ON COLUMN agents.performance_metrics IS 'æ€§èƒ½æŒ‡æ ‡ï¼ŒJSONå¯¹è±¡ï¼ŒåŒ…å«å“åº”æ—¶é—´ã€æˆåŠŸç‡ç­‰';
COMMENT ON COLUMN agents.config IS 'Agenté…ç½®ä¿¡æ¯ï¼ŒJSONå¯¹è±¡ï¼ŒåŒ…å«ä¸ªæ€§åŒ–è®¾ç½®';

-- ç´¢å¼•æ³¨é‡Š  
COMMENT ON INDEX idx_agents_role IS 'æŒ‰Agentè§’è‰²æŸ¥è¯¢çš„ç´¢å¼•ï¼Œç”¨äºè§’è‰²ç­›é€‰';
COMMENT ON INDEX idx_agents_status_created IS 'æŒ‰çŠ¶æ€å’Œåˆ›å»ºæ—¶é—´çš„å¤åˆç´¢å¼•ï¼Œç”¨äºæ´»è·ƒAgentæŸ¥è¯¢';
```

---

## ğŸ” æ•°æ®åº“ç»´æŠ¤å’Œç›‘æ§

### 1. æ€§èƒ½ç›‘æ§
```sql
-- æ…¢æŸ¥è¯¢ç›‘æ§
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
WHERE mean_time > 100  -- å¹³å‡æ‰§è¡Œæ—¶é—´è¶…è¿‡100ms
ORDER BY mean_time DESC;

-- ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_scan = 0;  -- æœªä½¿ç”¨çš„ç´¢å¼•

-- è¡¨å¤§å°ç›‘æ§
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### 2. å¤‡ä»½å’Œæ¢å¤ç­–ç•¥
```bash
#!/bin/bash
# æ•°æ®åº“å¤‡ä»½è„šæœ¬

DB_NAME="digital_employee"
BACKUP_DIR="/backup/database"
DATE=$(date +%Y%m%d_%H%M%S)

# å…¨é‡å¤‡ä»½
pg_dump -h localhost -U postgres -d $DB_NAME -f $BACKUP_DIR/full_backup_$DATE.sql

# å¢é‡å¤‡ä»½ (WAL)
pg_basebackup -h localhost -U postgres -D $BACKUP_DIR/base_backup_$DATE -Ft -z -P

# æ¸…ç†30å¤©å‰çš„å¤‡ä»½
find $BACKUP_DIR -name "*.sql" -mtime +30 -delete
```

---

è¿™å¥—å¼€å‘è§„èŒƒæ¶µç›–äº†æ•°å­—å‘˜å·¥ç³»ç»Ÿçš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œç¡®ä¿äº†ä»£ç è´¨é‡ã€ç³»ç»Ÿç¨³å®šæ€§å’Œå›¢é˜Ÿåä½œæ•ˆç‡ã€‚è¯·æ ¹æ®é¡¹ç›®å…·ä½“éœ€æ±‚è¿›è¡Œè°ƒæ•´å’Œè¡¥å……ã€‚