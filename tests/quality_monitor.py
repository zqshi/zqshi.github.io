"""
AIç³»ç»Ÿè´¨é‡ç›‘æ§å·¥å…·
å®æ—¶è´¨é‡æŒ‡æ ‡æ”¶é›†ã€åˆ†æå’ŒæŠ¥è­¦
"""

import json
import time
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import sqlite3
import statistics


class QualityLevel(Enum):
    """è´¨é‡ç­‰çº§"""
    EXCELLENT = "excellent"  # ä¼˜ç§€
    GOOD = "good"           # è‰¯å¥½  
    ACCEPTABLE = "acceptable"  # å¯æ¥å—
    POOR = "poor"           # å·®
    CRITICAL = "critical"   # ä¸¥é‡


@dataclass
class QualityMetric:
    """è´¨é‡æŒ‡æ ‡æ•°æ®ç»“æ„"""
    timestamp: datetime
    metric_type: str  # response_time, confidence_score, success_rate, etc.
    value: float
    context: Dict[str, Any]  # ä¸Šä¸‹æ–‡ä¿¡æ¯
    quality_level: QualityLevel


@dataclass
class QualityAlert:
    """è´¨é‡è­¦æŠ¥æ•°æ®ç»“æ„"""
    timestamp: datetime
    alert_type: str
    severity: str  # low, medium, high, critical
    message: str
    metric_data: Dict[str, Any]
    suggested_actions: List[str]


class QualityDatabase:
    """è´¨é‡æ•°æ®å­˜å‚¨"""
    
    def __init__(self, db_path: str = "quality_metrics.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        try:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS quality_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    metric_type TEXT NOT NULL,
                    value REAL NOT NULL,
                    quality_level TEXT NOT NULL,
                    context TEXT NOT NULL
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS quality_alerts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    alert_type TEXT NOT NULL,
                    severity TEXT NOT NULL,
                    message TEXT NOT NULL,
                    metric_data TEXT NOT NULL,
                    suggested_actions TEXT NOT NULL
                )
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_metrics_timestamp 
                ON quality_metrics(timestamp)
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_metrics_type 
                ON quality_metrics(metric_type)
            """)
            
            conn.commit()
        finally:
            conn.close()
    
    def save_metric(self, metric: QualityMetric):
        """ä¿å­˜è´¨é‡æŒ‡æ ‡"""
        conn = sqlite3.connect(self.db_path)
        try:
            conn.execute("""
                INSERT INTO quality_metrics 
                (timestamp, metric_type, value, quality_level, context)
                VALUES (?, ?, ?, ?, ?)
            """, (
                metric.timestamp.isoformat(),
                metric.metric_type,
                metric.value,
                metric.quality_level.value,
                json.dumps(metric.context)
            ))
            conn.commit()
        finally:
            conn.close()
    
    def save_alert(self, alert: QualityAlert):
        """ä¿å­˜è´¨é‡è­¦æŠ¥"""
        conn = sqlite3.connect(self.db_path)
        try:
            conn.execute("""
                INSERT INTO quality_alerts 
                (timestamp, alert_type, severity, message, metric_data, suggested_actions)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                alert.timestamp.isoformat(),
                alert.alert_type,
                alert.severity,
                alert.message,
                json.dumps(alert.metric_data),
                json.dumps(alert.suggested_actions)
            ))
            conn.commit()
        finally:
            conn.close()
    
    def get_metrics(self, metric_type: str = None, 
                   start_time: datetime = None, 
                   end_time: datetime = None) -> List[QualityMetric]:
        """è·å–è´¨é‡æŒ‡æ ‡æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        try:
            query = "SELECT timestamp, metric_type, value, quality_level, context FROM quality_metrics WHERE 1=1"
            params = []
            
            if metric_type:
                query += " AND metric_type = ?"
                params.append(metric_type)
            
            if start_time:
                query += " AND timestamp >= ?"
                params.append(start_time.isoformat())
            
            if end_time:
                query += " AND timestamp <= ?"
                params.append(end_time.isoformat())
            
            query += " ORDER BY timestamp DESC"
            
            cursor = conn.execute(query, params)
            rows = cursor.fetchall()
            
            metrics = []
            for row in rows:
                metrics.append(QualityMetric(
                    timestamp=datetime.fromisoformat(row[0]),
                    metric_type=row[1],
                    value=row[2],
                    quality_level=QualityLevel(row[3]),
                    context=json.loads(row[4])
                ))
            
            return metrics
        finally:
            conn.close()


class QualityThresholds:
    """è´¨é‡é˜ˆå€¼é…ç½®"""
    
    def __init__(self):
        self.thresholds = {
            "response_time": {
                QualityLevel.EXCELLENT: 1.0,
                QualityLevel.GOOD: 3.0,
                QualityLevel.ACCEPTABLE: 5.0,
                QualityLevel.POOR: 8.0,
                QualityLevel.CRITICAL: float('inf')
            },
            "confidence_score": {
                QualityLevel.EXCELLENT: 0.9,
                QualityLevel.GOOD: 0.8,
                QualityLevel.ACCEPTABLE: 0.7,
                QualityLevel.POOR: 0.6,
                QualityLevel.CRITICAL: 0.0
            },
            "success_rate": {
                QualityLevel.EXCELLENT: 0.99,
                QualityLevel.GOOD: 0.95,
                QualityLevel.ACCEPTABLE: 0.9,
                QualityLevel.POOR: 0.8,
                QualityLevel.CRITICAL: 0.0
            },
            "token_efficiency": {  # tokens per useful content length
                QualityLevel.EXCELLENT: 2.0,
                QualityLevel.GOOD: 3.0,
                QualityLevel.ACCEPTABLE: 4.0,
                QualityLevel.POOR: 6.0,
                QualityLevel.CRITICAL: float('inf')
            }
        }
    
    def evaluate_quality(self, metric_type: str, value: float) -> QualityLevel:
        """è¯„ä¼°è´¨é‡ç­‰çº§"""
        if metric_type not in self.thresholds:
            return QualityLevel.ACCEPTABLE
        
        thresholds = self.thresholds[metric_type]
        
        # å¯¹äºå“åº”æ—¶é—´å’Œtokenæ•ˆç‡ï¼Œå€¼è¶Šå°è¶Šå¥½
        if metric_type in ["response_time", "token_efficiency"]:
            for level in [QualityLevel.EXCELLENT, QualityLevel.GOOD, 
                         QualityLevel.ACCEPTABLE, QualityLevel.POOR]:
                if value <= thresholds[level]:
                    return level
            return QualityLevel.CRITICAL
        
        # å¯¹äºç½®ä¿¡åº¦å’ŒæˆåŠŸç‡ï¼Œå€¼è¶Šå¤§è¶Šå¥½
        else:
            for level in [QualityLevel.EXCELLENT, QualityLevel.GOOD, 
                         QualityLevel.ACCEPTABLE, QualityLevel.POOR]:
                if value >= thresholds[level]:
                    return level
            return QualityLevel.CRITICAL
    
    def get_threshold(self, metric_type: str, level: QualityLevel) -> float:
        """è·å–ç‰¹å®šè´¨é‡ç­‰çº§çš„é˜ˆå€¼"""
        return self.thresholds.get(metric_type, {}).get(level, 0.0)


class QualityAnalyzer:
    """è´¨é‡åˆ†æå™¨"""
    
    def __init__(self, db: QualityDatabase, thresholds: QualityThresholds):
        self.db = db
        self.thresholds = thresholds
        self.logger = logging.getLogger(__name__)
    
    def analyze_trend(self, metric_type: str, time_window: timedelta = timedelta(hours=1)) -> Dict[str, Any]:
        """åˆ†æè´¨é‡è¶‹åŠ¿"""
        end_time = datetime.now()
        start_time = end_time - time_window
        
        metrics = self.db.get_metrics(metric_type, start_time, end_time)
        
        if len(metrics) < 2:
            return {"status": "insufficient_data", "count": len(metrics)}
        
        values = [m.value for m in metrics]
        timestamps = [m.timestamp for m in metrics]
        
        # è®¡ç®—è¶‹åŠ¿
        first_half = values[:len(values)//2]
        second_half = values[len(values)//2:]
        
        first_avg = statistics.mean(first_half)
        second_avg = statistics.mean(second_half)
        
        trend_percentage = (second_avg - first_avg) / first_avg * 100 if first_avg > 0 else 0
        
        # åˆ¤æ–­è¶‹åŠ¿æ–¹å‘
        if abs(trend_percentage) < 5:
            trend_direction = "stable"
        elif trend_percentage > 0:
            trend_direction = "increasing" if metric_type in ["confidence_score", "success_rate"] else "degrading"
        else:
            trend_direction = "decreasing" if metric_type in ["confidence_score", "success_rate"] else "improving"
        
        return {
            "metric_type": metric_type,
            "time_window": str(time_window),
            "sample_count": len(metrics),
            "current_avg": statistics.mean(values),
            "trend_percentage": trend_percentage,
            "trend_direction": trend_direction,
            "first_half_avg": first_avg,
            "second_half_avg": second_avg,
            "min_value": min(values),
            "max_value": max(values),
            "std_dev": statistics.stdev(values) if len(values) > 1 else 0
        }
    
    def detect_anomalies(self, metric_type: str, time_window: timedelta = timedelta(minutes=30)) -> List[QualityMetric]:
        """æ£€æµ‹è´¨é‡å¼‚å¸¸"""
        end_time = datetime.now()
        start_time = end_time - time_window
        
        metrics = self.db.get_metrics(metric_type, start_time, end_time)
        
        if len(metrics) < 10:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®ç‚¹
            return []
        
        values = [m.value for m in metrics]
        mean_val = statistics.mean(values)
        std_val = statistics.stdev(values) if len(values) > 1 else 0
        
        # ä½¿ç”¨3-sigmaè§„åˆ™æ£€æµ‹å¼‚å¸¸
        anomalies = []
        for metric in metrics:
            if std_val > 0:
                z_score = abs(metric.value - mean_val) / std_val
                if z_score > 3:  # 3-sigmaå¼‚å¸¸
                    anomalies.append(metric)
        
        return anomalies
    
    def generate_quality_report(self, time_window: timedelta = timedelta(hours=24)) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        end_time = datetime.now()
        start_time = end_time - time_window
        
        report = {
            "report_time": end_time.isoformat(),
            "time_window": str(time_window),
            "metrics_summary": {},
            "trends": {},
            "anomalies": {},
            "alerts": [],
            "overall_health": "unknown"
        }
        
        # åˆ†æå„ç±»æŒ‡æ ‡
        metric_types = ["response_time", "confidence_score", "success_rate", "token_efficiency"]
        
        for metric_type in metric_types:
            metrics = self.db.get_metrics(metric_type, start_time, end_time)
            
            if not metrics:
                continue
            
            values = [m.value for m in metrics]
            
            report["metrics_summary"][metric_type] = {
                "count": len(metrics),
                "average": statistics.mean(values),
                "median": statistics.median(values),
                "min": min(values),
                "max": max(values),
                "std_dev": statistics.stdev(values) if len(values) > 1 else 0
            }
            
            # è¶‹åŠ¿åˆ†æ
            report["trends"][metric_type] = self.analyze_trend(metric_type, time_window)
            
            # å¼‚å¸¸æ£€æµ‹
            anomalies = self.detect_anomalies(metric_type, time_window)
            if anomalies:
                report["anomalies"][metric_type] = len(anomalies)
        
        # è®¡ç®—æ•´ä½“å¥åº·åº¦
        report["overall_health"] = self._calculate_overall_health(report)
        
        return report
    
    def _calculate_overall_health(self, report: Dict[str, Any]) -> str:
        """è®¡ç®—æ•´ä½“å¥åº·åº¦"""
        if not report["metrics_summary"]:
            return "unknown"
        
        health_scores = []
        
        # åŸºäºå„æŒ‡æ ‡çš„è¡¨ç°è¯„åˆ†
        for metric_type, summary in report["metrics_summary"].items():
            avg_value = summary["average"]
            quality_level = self.thresholds.evaluate_quality(metric_type, avg_value)
            
            # è½¬æ¢ä¸ºæ•°å€¼åˆ†æ•°
            score_map = {
                QualityLevel.EXCELLENT: 100,
                QualityLevel.GOOD: 80,
                QualityLevel.ACCEPTABLE: 60,
                QualityLevel.POOR: 40,
                QualityLevel.CRITICAL: 20
            }
            health_scores.append(score_map[quality_level])
        
        if not health_scores:
            return "unknown"
        
        overall_score = statistics.mean(health_scores)
        
        if overall_score >= 90:
            return "excellent"
        elif overall_score >= 75:
            return "good"
        elif overall_score >= 60:
            return "acceptable"
        elif overall_score >= 40:
            return "poor"
        else:
            return "critical"


class QualityMonitor:
    """è´¨é‡ç›‘æ§å™¨ä¸»ç±»"""
    
    def __init__(self, db_path: str = "quality_metrics.db"):
        self.db = QualityDatabase(db_path)
        self.thresholds = QualityThresholds()
        self.analyzer = QualityAnalyzer(self.db, self.thresholds)
        self.alert_handlers = []
        self.logger = logging.getLogger(__name__)
        
        # ç›‘æ§é…ç½®
        self.monitoring_enabled = True
        self.alert_cooldown = {}  # é¿å…é‡å¤æŠ¥è­¦
        self.cooldown_period = timedelta(minutes=15)
    
    def add_alert_handler(self, handler):
        """æ·»åŠ è­¦æŠ¥å¤„ç†å™¨"""
        self.alert_handlers.append(handler)
    
    def record_metric(self, metric_type: str, value: float, context: Dict[str, Any] = None):
        """è®°å½•è´¨é‡æŒ‡æ ‡"""
        if not self.monitoring_enabled:
            return
        
        timestamp = datetime.now()
        context = context or {}
        
        # è¯„ä¼°è´¨é‡ç­‰çº§
        quality_level = self.thresholds.evaluate_quality(metric_type, value)
        
        # åˆ›å»ºæŒ‡æ ‡è®°å½•
        metric = QualityMetric(
            timestamp=timestamp,
            metric_type=metric_type,
            value=value,
            context=context,
            quality_level=quality_level
        )
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        self.db.save_metric(metric)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘å‡ºè­¦æŠ¥
        self._check_alert_conditions(metric)
        
        self.logger.debug(f"è®°å½•è´¨é‡æŒ‡æ ‡: {metric_type}={value} ({quality_level.value})")
    
    def _check_alert_conditions(self, metric: QualityMetric):
        """æ£€æŸ¥è­¦æŠ¥æ¡ä»¶"""
        
        # ä¸¥é‡è´¨é‡é—®é¢˜ç«‹å³æŠ¥è­¦
        if metric.quality_level in [QualityLevel.POOR, QualityLevel.CRITICAL]:
            self._trigger_alert(
                alert_type="quality_degradation",
                severity="high" if metric.quality_level == QualityLevel.POOR else "critical",
                message=f"{metric.metric_type}è´¨é‡{metric.quality_level.value}: {metric.value}",
                metric_data=asdict(metric),
                suggested_actions=self._get_suggested_actions(metric)
            )
        
        # æ£€æŸ¥è¶‹åŠ¿è­¦æŠ¥
        trend_analysis = self.analyzer.analyze_trend(metric.metric_type, timedelta(minutes=30))
        
        if trend_analysis.get("trend_direction") == "degrading" and abs(trend_analysis.get("trend_percentage", 0)) > 20:
            self._trigger_alert(
                alert_type="quality_trend_degradation",
                severity="medium",
                message=f"{metric.metric_type}è´¨é‡å‘ˆä¸‹é™è¶‹åŠ¿: {trend_analysis['trend_percentage']:.1f}%",
                metric_data=trend_analysis,
                suggested_actions=["æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½", "éªŒè¯AIæœåŠ¡çŠ¶æ€", "åˆ†ææœ€è¿‘çš„ä»£ç å˜æ›´"]
            )
    
    def _trigger_alert(self, alert_type: str, severity: str, message: str, 
                      metric_data: Dict[str, Any], suggested_actions: List[str]):
        """è§¦å‘è­¦æŠ¥"""
        
        # æ£€æŸ¥å†·å´æœŸï¼Œé¿å…é‡å¤æŠ¥è­¦
        alert_key = f"{alert_type}_{severity}"
        now = datetime.now()
        
        if alert_key in self.alert_cooldown:
            if now - self.alert_cooldown[alert_key] < self.cooldown_period:
                return  # åœ¨å†·å´æœŸå†…ï¼Œè·³è¿‡æŠ¥è­¦
        
        self.alert_cooldown[alert_key] = now
        
        # åˆ›å»ºè­¦æŠ¥
        alert = QualityAlert(
            timestamp=now,
            alert_type=alert_type,
            severity=severity,
            message=message,
            metric_data=metric_data,
            suggested_actions=suggested_actions
        )
        
        # ä¿å­˜è­¦æŠ¥
        self.db.save_alert(alert)
        
        # é€šçŸ¥è­¦æŠ¥å¤„ç†å™¨
        for handler in self.alert_handlers:
            try:
                handler(alert)
            except Exception as e:
                self.logger.error(f"è­¦æŠ¥å¤„ç†å™¨é”™è¯¯: {e}")
        
        self.logger.warning(f"è´¨é‡è­¦æŠ¥: {alert_type} - {message}")
    
    def _get_suggested_actions(self, metric: QualityMetric) -> List[str]:
        """è·å–å»ºè®®çš„ä¿®å¤è¡ŒåŠ¨"""
        actions_map = {
            "response_time": [
                "æ£€æŸ¥AIæœåŠ¡å“åº”å»¶è¿Ÿ",
                "éªŒè¯ç½‘ç»œè¿æ¥çŠ¶æ€",
                "è€ƒè™‘å¢åŠ æœåŠ¡å™¨èµ„æº",
                "ä¼˜åŒ–è¯·æ±‚æ‰¹å¤„ç†"
            ],
            "confidence_score": [
                "æ£€æŸ¥è¾“å…¥æ•°æ®è´¨é‡",
                "éªŒè¯promptæ¨¡æ¿",
                "è€ƒè™‘è°ƒæ•´æ¨¡å‹å‚æ•°",
                "åˆ†æå¤±è´¥æ¡ˆä¾‹"
            ],
            "success_rate": [
                "æ£€æŸ¥é”™è¯¯æ—¥å¿—",
                "éªŒè¯APIå¯†é’¥å’Œé…é¢",
                "æµ‹è¯•å¤‡ç”¨æœåŠ¡",
                "æ£€æŸ¥è¾“å…¥éªŒè¯é€»è¾‘"
            ],
            "token_efficiency": [
                "ä¼˜åŒ–prompté•¿åº¦",
                "æ£€æŸ¥å“åº”æ ¼å¼",
                "è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹",
                "å®æ–½å“åº”ç¼“å­˜"
            ]
        }
        
        return actions_map.get(metric.metric_type, ["è”ç³»æŠ€æœ¯æ”¯æŒ", "æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—"])
    
    def get_dashboard_data(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§ä»ªè¡¨æ¿æ•°æ®"""
        report = self.analyzer.generate_quality_report(timedelta(hours=24))
        
        # æ·»åŠ å®æ—¶çŠ¶æ€
        recent_metrics = {}
        for metric_type in ["response_time", "confidence_score", "success_rate"]:
            metrics = self.db.get_metrics(metric_type, datetime.now() - timedelta(minutes=5))
            if metrics:
                recent_metrics[metric_type] = {
                    "current_value": metrics[0].value,
                    "quality_level": metrics[0].quality_level.value,
                    "sample_count": len(metrics)
                }
        
        return {
            "real_time_status": recent_metrics,
            "daily_report": report,
            "system_health": report["overall_health"]
        }


# ä¾¿æ·çš„å…¨å±€ç›‘æ§å™¨å®ä¾‹
global_quality_monitor = QualityMonitor()


def simple_alert_handler(alert: QualityAlert):
    """ç®€å•çš„æ§åˆ¶å°è­¦æŠ¥å¤„ç†å™¨"""
    print(f"\nğŸš¨ è´¨é‡è­¦æŠ¥ [{alert.severity.upper()}] - {alert.timestamp}")
    print(f"ç±»å‹: {alert.alert_type}")
    print(f"æ¶ˆæ¯: {alert.message}")
    print("å»ºè®®è¡ŒåŠ¨:")
    for action in alert.suggested_actions:
        print(f"  - {action}")
    print("-" * 50)


# æ³¨å†Œé»˜è®¤è­¦æŠ¥å¤„ç†å™¨
global_quality_monitor.add_alert_handler(simple_alert_handler)


# ä¾¿æ·å‡½æ•°
def record_response_time(value: float, context: Dict[str, Any] = None):
    """è®°å½•å“åº”æ—¶é—´"""
    global_quality_monitor.record_metric("response_time", value, context)


def record_confidence_score(value: float, context: Dict[str, Any] = None):
    """è®°å½•ç½®ä¿¡åº¦åˆ†æ•°"""
    global_quality_monitor.record_metric("confidence_score", value, context)


def record_success_rate(value: float, context: Dict[str, Any] = None):
    """è®°å½•æˆåŠŸç‡"""
    global_quality_monitor.record_metric("success_rate", value, context)


def get_quality_dashboard():
    """è·å–è´¨é‡ä»ªè¡¨æ¿æ•°æ®"""
    return global_quality_monitor.get_dashboard_data()


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    monitor = QualityMonitor()
    
    # æ¨¡æ‹Ÿä¸€äº›è´¨é‡æ•°æ®
    import random
    for i in range(100):
        monitor.record_metric("response_time", random.uniform(0.5, 3.0))
        monitor.record_metric("confidence_score", random.uniform(0.6, 0.95))
        monitor.record_metric("success_rate", random.uniform(0.85, 1.0))
    
    # ç”ŸæˆæŠ¥å‘Š
    dashboard = monitor.get_dashboard_data()
    print(json.dumps(dashboard, indent=2, default=str))